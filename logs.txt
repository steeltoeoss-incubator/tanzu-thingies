
==> Audit <==
|---------|--------------------------------|----------|-----------------|---------|---------------------|---------------------|
| Command |              Args              | Profile  |      User       | Version |     Start Time      |      End Time       |
|---------|--------------------------------|----------|-----------------|---------|---------------------|---------------------|
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 14 Sep 22 16:42 EDT | 14 Sep 22 16:43 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 14 Sep 22 16:43 EDT | 14 Sep 22 16:44 EDT |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 14 Sep 22 16:45 EDT | 14 Sep 22 16:45 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 14 Sep 22 16:45 EDT | 14 Sep 22 16:45 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 14 Sep 22 16:46 EDT | 16 Sep 22 08:10 EDT |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 08:10 EDT | 16 Sep 22 09:44 EDT |
| stop    |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 09:44 EDT | 16 Sep 22 09:45 EDT |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 09:45 EDT | 16 Sep 22 09:45 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 14:23 EDT |                     |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=12g          |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 14:24 EDT | 16 Sep 22 14:24 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| stop    |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 14:25 EDT | 16 Sep 22 14:25 EDT |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 14:25 EDT | 16 Sep 22 14:25 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 14:25 EDT | 16 Sep 22 14:28 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 14:28 EDT | 16 Sep 22 14:56 EDT |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 14:56 EDT | 16 Sep 22 14:56 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 14:56 EDT | 16 Sep 22 14:56 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 14:57 EDT | 16 Sep 22 15:00 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 15:00 EDT | 16 Sep 22 15:01 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 15:01 EDT | 16 Sep 22 15:12 EDT |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 15:12 EDT | 16 Sep 22 15:12 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 15:13 EDT | 16 Sep 22 15:13 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| stop    |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 15:14 EDT | 16 Sep 22 15:14 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 15:14 EDT | 16 Sep 22 15:14 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 15:15 EDT | 16 Sep 22 15:51 EDT |
| stop    |                                | minikube | ALIEN\ccheetham | v1.26.1 | 16 Sep 22 15:51 EDT | 16 Sep 22 15:51 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 06:54 EDT | 17 Sep 22 06:55 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 07:06 EDT | 17 Sep 22 08:23 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 08:23 EDT | 17 Sep 22 08:24 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| stop    |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 08:24 EDT | 17 Sep 22 08:25 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 08:25 EDT | 17 Sep 22 08:25 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 08:27 EDT | 17 Sep 22 08:38 EDT |
| stop    |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 08:38 EDT | 17 Sep 22 08:38 EDT |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 08:39 EDT | 17 Sep 22 08:39 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 08:39 EDT | 17 Sep 22 08:40 EDT |
|         | --kubernetes-version=1.23.8    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 08:56 EDT |                     |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 09:35 EDT | 17 Sep 22 09:41 EDT |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| stop    |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 09:42 EDT | 17 Sep 22 09:42 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 09:42 EDT | 17 Sep 22 09:42 EDT |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 09:49 EDT | 17 Sep 22 09:49 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 09:50 EDT | 17 Sep 22 09:51 EDT |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 09:51 EDT |                     |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 09:55 EDT | 17 Sep 22 09:55 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 09:55 EDT | 17 Sep 22 09:55 EDT |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 09:56 EDT |                     |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 10:23 EDT | 17 Sep 22 10:23 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 10:23 EDT | 17 Sep 22 10:24 EDT |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 10:31 EDT | 17 Sep 22 10:38 EDT |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 10:39 EDT | 17 Sep 22 10:39 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 10:40 EDT | 17 Sep 22 10:40 EDT |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 17 Sep 22 10:41 EDT | 18 Sep 22 09:13 EDT |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 09:13 EDT | 18 Sep 22 09:14 EDT |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 13:53 EDT |                     |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 13:55 EDT |                     |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 13:56 EDT |                     |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 13:56 EDT |                     |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 13:56 EDT | 18 Sep 22 13:57 EDT |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 13:57 EDT |                     |
| delete  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 14:27 EDT | 18 Sep 22 14:28 EDT |
| start   | --driver=docker                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 14:28 EDT | 18 Sep 22 14:28 EDT |
|         | --kubernetes-version=1.24.3    |          |                 |         |                     |                     |
|         | --cpus=8 --memory=8g           |          |                 |         |                     |                     |
|         | --disk-size=12g                |          |                 |         |                     |                     |
| tunnel  |                                | minikube | ALIEN\ccheetham | v1.26.1 | 18 Sep 22 14:28 EDT |                     |
|---------|--------------------------------|----------|-----------------|---------|---------------------|---------------------|


==> Last Start <==
Log file created at: 2022/09/18 14:28:11
Running on machine: alien
Binary: Built with gc go1.18.3 for windows/amd64
Log line format: [IWEF]mmdd hh:mm:ss.uuuuuu threadid file:line] msg
I0918 14:28:11.300104   27256 out.go:296] Setting OutFile to fd 80 ...
I0918 14:28:11.300623   27256 out.go:309] Setting ErrFile to fd 88...
I0918 14:28:11.320419   27256 out.go:303] Setting JSON to false
I0918 14:28:11.329497   27256 start.go:115] hostinfo: {"hostname":"alien","uptime":15074,"bootTime":1663510617,"procs":359,"os":"windows","platform":"Microsoft Windows 11 Home","platformFamily":"Standalone Workstation","platformVersion":"10.0.22000 Build 22000","kernelVersion":"10.0.22000 Build 22000","kernelArch":"x86_64","virtualizationSystem":"","virtualizationRole":"","hostId":"b94d350e-99b5-4d01-9574-a21f46ebe898"}
W0918 14:28:11.329497   27256 start.go:123] gopshost.Virtualization returned error: not implemented yet
I0918 14:28:11.332168   27256 out.go:177] üòÑ  minikube v1.26.1 on Microsoft Windows 11 Home 10.0.22000 Build 22000
I0918 14:28:11.335802   27256 notify.go:193] Checking for updates...
I0918 14:28:11.336319   27256 driver.go:365] Setting default libvirt URI to qemu:///system
I0918 14:28:11.494056   27256 docker.go:137] docker version: linux-20.10.17
I0918 14:28:11.500318   27256 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0918 14:28:13.489915   27256 cli_runner.go:217] Completed: docker system info --format "{{json .}}": (1.9895971s)
I0918 14:28:13.491639   27256 info.go:265] docker info: {ID:OCC5:ONQL:JTXM:5SZL:CWMW:4XWF:K3GY:LHAD:A3CI:S3YJ:KGXW:ZY5L Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:12 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:48 OomKillDisable:true NGoroutines:52 SystemTime:2022-09-18 18:28:11.5992894 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.10.102.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:12550451200 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 Expected:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.9.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.10.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.9] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.19.0]] Warnings:<nil>}}
I0918 14:28:13.493745   27256 out.go:177] ‚ú®  Using the docker driver based on user configuration
I0918 14:28:13.497421   27256 start.go:284] selected driver: docker
I0918 14:28:13.497421   27256 start.go:808] validating driver "docker" against <nil>
I0918 14:28:13.497421   27256 start.go:819] status for docker: {Installed:true Healthy:true Running:false NeedsImprovement:false Error:<nil> Reason: Fix: Doc: Version:}
I0918 14:28:13.651221   27256 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0918 14:28:14.077632   27256 info.go:265] docker info: {ID:OCC5:ONQL:JTXM:5SZL:CWMW:4XWF:K3GY:LHAD:A3CI:S3YJ:KGXW:ZY5L Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:12 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:48 OomKillDisable:true NGoroutines:52 SystemTime:2022-09-18 18:28:13.769066 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.10.102.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:12550451200 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 Expected:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.9.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.10.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.9] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.19.0]] Warnings:<nil>}}
I0918 14:28:14.078137   27256 start_flags.go:296] no existing cluster config was found, will generate one from the flags 
I0918 14:28:14.078664   27256 start_flags.go:835] Wait components to verify : map[apiserver:true system_pods:true]
I0918 14:28:14.080766   27256 out.go:177] üìå  Using Docker Desktop driver with root privileges
I0918 14:28:14.082855   27256 cni.go:95] Creating CNI manager for ""
I0918 14:28:14.082855   27256 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0918 14:28:14.082855   27256 start_flags.go:310] config:
{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:8192 CPUs:8 DiskSize:12288 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\ccheetham:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0918 14:28:14.085497   27256 out.go:177] üëç  Starting control plane node minikube in cluster minikube
I0918 14:28:14.089673   27256 cache.go:120] Beginning downloading kic base image for docker with docker
I0918 14:28:14.091325   27256 out.go:177] üöú  Pulling base image ...
I0918 14:28:14.095617   27256 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0918 14:28:14.095617   27256 image.go:75] Checking for gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon
I0918 14:28:14.096668   27256 preload.go:148] Found local preload: C:\Users\ccheetham\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4
I0918 14:28:14.096668   27256 cache.go:57] Caching tarball of preloaded images
I0918 14:28:14.097191   27256 preload.go:174] Found C:\Users\ccheetham\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4 in cache, skipping download
I0918 14:28:14.097191   27256 cache.go:60] Finished verifying existence of preloaded tar for  v1.24.3 on docker
I0918 14:28:14.097191   27256 profile.go:148] Saving config to C:\Users\ccheetham\.minikube\profiles\minikube\config.json ...
I0918 14:28:14.097715   27256 lock.go:35] WriteFile acquiring C:\Users\ccheetham\.minikube\profiles\minikube\config.json: {Name:mk67a1387adb231f1917823c37a20a3ecac984c6 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0918 14:28:14.247802   27256 image.go:79] Found gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 in local docker daemon, skipping pull
I0918 14:28:14.247802   27256 cache.go:142] gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 exists in daemon, skipping load
I0918 14:28:14.247802   27256 cache.go:208] Successfully downloaded all kic artifacts
I0918 14:28:14.247802   27256 start.go:371] acquiring machines lock for minikube: {Name:mk322d0c088d867e5ae99129245d87b2efcefb83 Clock:{} Delay:500ms Timeout:10m0s Cancel:<nil>}
I0918 14:28:14.248308   27256 start.go:375] acquired machines lock for "minikube" in 506¬µs
I0918 14:28:14.248308   27256 start.go:92] Provisioning new machine with config: &{Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:8192 CPUs:8 DiskSize:12288 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP: Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\ccheetham:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:} &{Name: IP: Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0918 14:28:14.248851   27256 start.go:132] createHost starting for "" (driver="docker")
I0918 14:28:14.250937   27256 out.go:204] üî•  Creating docker container (CPUs=8, Memory=8192MB) ...
I0918 14:28:14.251975   27256 start.go:166] libmachine.API.Create for "minikube" (driver="docker")
I0918 14:28:14.251975   27256 client.go:168] LocalClient.Create starting
I0918 14:28:14.253546   27256 main.go:134] libmachine: Reading certificate data from C:\Users\ccheetham\.minikube\certs\ca.pem
I0918 14:28:14.254070   27256 main.go:134] libmachine: Decoding PEM data...
I0918 14:28:14.254070   27256 main.go:134] libmachine: Parsing certificate...
I0918 14:28:14.254596   27256 main.go:134] libmachine: Reading certificate data from C:\Users\ccheetham\.minikube\certs\cert.pem
I0918 14:28:14.254596   27256 main.go:134] libmachine: Decoding PEM data...
I0918 14:28:14.254596   27256 main.go:134] libmachine: Parsing certificate...
I0918 14:28:14.264142   27256 cli_runner.go:164] Run: docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
W0918 14:28:14.417231   27256 cli_runner.go:211] docker network inspect minikube --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}" returned with exit code 1
I0918 14:28:14.424110   27256 network_create.go:272] running [docker network inspect minikube] to gather additional debugging logs...
I0918 14:28:14.424110   27256 cli_runner.go:164] Run: docker network inspect minikube
W0918 14:28:14.554677   27256 cli_runner.go:211] docker network inspect minikube returned with exit code 1
I0918 14:28:14.554677   27256 network_create.go:275] error running [docker network inspect minikube]: docker network inspect minikube: exit status 1
stdout:
[]

stderr:
Error: No such network: minikube
I0918 14:28:14.554677   27256 network_create.go:277] output of [docker network inspect minikube]: -- stdout --
[]

-- /stdout --
** stderr ** 
Error: No such network: minikube

** /stderr **
I0918 14:28:14.561503   27256 cli_runner.go:164] Run: docker network inspect bridge --format "{"Name": "{{.Name}}","Driver": "{{.Driver}}","Subnet": "{{range .IPAM.Config}}{{.Subnet}}{{end}}","Gateway": "{{range .IPAM.Config}}{{.Gateway}}{{end}}","MTU": {{if (index .Options "com.docker.network.driver.mtu")}}{{(index .Options "com.docker.network.driver.mtu")}}{{else}}0{{end}}, "ContainerIPs": [{{range $k,$v := .Containers }}"{{$v.IPv4Address}}",{{end}}]}"
I0918 14:28:14.784818   27256 network.go:288] reserving subnet 192.168.49.0 for 1m0s: &{mu:{state:0 sema:0} read:{v:{m:map[] amended:true}} dirty:map[192.168.49.0:0xc000111ab8] misses:0}
I0918 14:28:14.785839   27256 network.go:235] using free private subnet 192.168.49.0/24: &{IP:192.168.49.0 Netmask:255.255.255.0 Prefix:24 CIDR:192.168.49.0/24 Gateway:192.168.49.1 ClientMin:192.168.49.2 ClientMax:192.168.49.254 Broadcast:192.168.49.255 Interface:{IfaceName: IfaceIPv4: IfaceMTU:0 IfaceMAC:}}
I0918 14:28:14.785839   27256 network_create.go:115] attempt to create docker network minikube 192.168.49.0/24 with gateway 192.168.49.1 and MTU of 1500 ...
I0918 14:28:14.792819   27256 cli_runner.go:164] Run: docker network create --driver=bridge --subnet=192.168.49.0/24 --gateway=192.168.49.1 -o --ip-masq -o --icc -o com.docker.network.driver.mtu=1500 --label=created_by.minikube.sigs.k8s.io=true --label=name.minikube.sigs.k8s.io=minikube minikube
I0918 14:28:14.991366   27256 network_create.go:99] docker network minikube 192.168.49.0/24 created
I0918 14:28:14.991366   27256 kic.go:106] calculated static IP "192.168.49.2" for the "minikube" container
I0918 14:28:15.008456   27256 cli_runner.go:164] Run: docker ps -a --format {{.Names}}
I0918 14:28:15.167776   27256 cli_runner.go:164] Run: docker volume create minikube --label name.minikube.sigs.k8s.io=minikube --label created_by.minikube.sigs.k8s.io=true
I0918 14:28:15.314051   27256 oci.go:103] Successfully created a docker volume minikube
I0918 14:28:15.320935   27256 cli_runner.go:164] Run: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib
I0918 14:28:16.970477   27256 cli_runner.go:217] Completed: docker run --rm --name minikube-preload-sidecar --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --entrypoint /usr/bin/test -v minikube:/var gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -d /var/lib: (1.6495422s)
I0918 14:28:16.970477   27256 oci.go:107] Successfully prepared a docker volume minikube
I0918 14:28:16.970477   27256 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0918 14:28:16.970477   27256 kic.go:179] Starting extracting preloaded images to volume ...
I0918 14:28:16.977342   27256 cli_runner.go:164] Run: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\ccheetham\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir
I0918 14:28:27.352505   27256 cli_runner.go:217] Completed: docker run --rm --entrypoint /usr/bin/tar -v C:\Users\ccheetham\.minikube\cache\preloaded-tarball\preloaded-images-k8s-v18-v1.24.3-docker-overlay2-amd64.tar.lz4:/preloaded.tar:ro -v minikube:/extractDir gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 -I lz4 -xf /preloaded.tar -C /extractDir: (10.3751628s)
I0918 14:28:27.352505   27256 kic.go:188] duration metric: took 10.382028 seconds to extract preloaded images to volume
I0918 14:28:27.359001   27256 cli_runner.go:164] Run: docker system info --format "{{json .}}"
I0918 14:28:27.782718   27256 info.go:265] docker info: {ID:OCC5:ONQL:JTXM:5SZL:CWMW:4XWF:K3GY:LHAD:A3CI:S3YJ:KGXW:ZY5L Containers:0 ContainersRunning:0 ContainersPaused:0 ContainersStopped:0 Images:12 Driver:overlay2 DriverStatus:[[Backing Filesystem extfs] [Supports d_type true] [Native Overlay Diff true] [userxattr false]] SystemStatus:<nil> Plugins:{Volume:[local] Network:[bridge host ipvlan macvlan null overlay] Authorization:<nil> Log:[awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog]} MemoryLimit:true SwapLimit:true KernelMemory:true KernelMemoryTCP:true CPUCfsPeriod:true CPUCfsQuota:true CPUShares:true CPUSet:true PidsLimit:true IPv4Forwarding:true BridgeNfIptables:true BridgeNfIP6Tables:true Debug:false NFd:48 OomKillDisable:true NGoroutines:52 SystemTime:2022-09-18 18:28:27.4938088 +0000 UTC LoggingDriver:json-file CgroupDriver:cgroupfs NEventsListener:5 KernelVersion:5.10.102.1-microsoft-standard-WSL2 OperatingSystem:Docker Desktop OSType:linux Architecture:x86_64 IndexServerAddress:https://index.docker.io/v1/ RegistryConfig:{AllowNondistributableArtifactsCIDRs:[] AllowNondistributableArtifactsHostnames:[] InsecureRegistryCIDRs:[127.0.0.0/8] IndexConfigs:{DockerIo:{Name:docker.io Mirrors:[] Secure:true Official:true}} Mirrors:[]} NCPU:8 MemTotal:12550451200 GenericResources:<nil> DockerRootDir:/var/lib/docker HTTPProxy:http.docker.internal:3128 HTTPSProxy:http.docker.internal:3128 NoProxy:hubproxy.docker.internal Name:docker-desktop Labels:[] ExperimentalBuild:false ServerVersion:20.10.17 ClusterStore: ClusterAdvertise: Runtimes:{Runc:{Path:runc}} DefaultRuntime:runc Swarm:{NodeID: NodeAddr: LocalNodeState:inactive ControlAvailable:false Error: RemoteManagers:<nil>} LiveRestoreEnabled:false Isolation: InitBinary:docker-init ContainerdCommit:{ID:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6 Expected:9cd3357b7fd7218e4aec3eae239db1f68a5a6ec6} RuncCommit:{ID:v1.1.4-0-g5fd4c4d Expected:v1.1.4-0-g5fd4c4d} InitCommit:{ID:de40ad0 Expected:de40ad0} SecurityOptions:[name=seccomp,profile=default] ProductLicense: Warnings:[WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support] ServerErrors:[] ClientInfo:{Debug:false Plugins:[map[Name:buildx Path:C:\Program Files\Docker\cli-plugins\docker-buildx.exe SchemaVersion:0.1.0 ShortDescription:Docker Buildx Vendor:Docker Inc. Version:v0.9.1] map[Name:compose Path:C:\Program Files\Docker\cli-plugins\docker-compose.exe SchemaVersion:0.1.0 ShortDescription:Docker Compose Vendor:Docker Inc. Version:v2.10.2] map[Name:extension Path:C:\Program Files\Docker\cli-plugins\docker-extension.exe SchemaVersion:0.1.0 ShortDescription:Manages Docker extensions Vendor:Docker Inc. Version:v0.2.9] map[Name:sbom Path:C:\Program Files\Docker\cli-plugins\docker-sbom.exe SchemaVersion:0.1.0 ShortDescription:View the packaged-based Software Bill Of Materials (SBOM) for an image URL:https://github.com/docker/sbom-cli-plugin Vendor:Anchore Inc. Version:0.6.0] map[Name:scan Path:C:\Program Files\Docker\cli-plugins\docker-scan.exe SchemaVersion:0.1.0 ShortDescription:Docker Scan Vendor:Docker Inc. Version:v0.19.0]] Warnings:<nil>}}
I0918 14:28:27.788875   27256 cli_runner.go:164] Run: docker info --format "'{{json .SecurityOptions}}'"
I0918 14:28:28.174232   27256 cli_runner.go:164] Run: docker run -d -t --privileged --security-opt seccomp=unconfined --tmpfs /tmp --tmpfs /run -v /lib/modules:/lib/modules:ro --hostname minikube --name minikube --label created_by.minikube.sigs.k8s.io=true --label name.minikube.sigs.k8s.io=minikube --label role.minikube.sigs.k8s.io= --label mode.minikube.sigs.k8s.io=minikube --network minikube --ip 192.168.49.2 --volume minikube:/var --security-opt apparmor=unconfined --memory=8192mb --memory-swap=8192mb --cpus=8 -e container=docker --expose 8443 --publish=127.0.0.1::8443 --publish=127.0.0.1::22 --publish=127.0.0.1::2376 --publish=127.0.0.1::5000 --publish=127.0.0.1::32443 gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8
I0918 14:28:28.911097   27256 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Running}}
I0918 14:28:29.048428   27256 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0918 14:28:29.187059   27256 cli_runner.go:164] Run: docker exec minikube stat /var/lib/dpkg/alternatives/iptables
I0918 14:28:29.443477   27256 oci.go:144] the created container "minikube" has a running status.
I0918 14:28:29.443477   27256 kic.go:210] Creating ssh key for kic: C:\Users\ccheetham\.minikube\machines\minikube\id_rsa...
I0918 14:28:29.626667   27256 kic_runner.go:191] docker (temp): C:\Users\ccheetham\.minikube\machines\minikube\id_rsa.pub --> /home/docker/.ssh/authorized_keys (381 bytes)
I0918 14:28:29.847208   27256 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0918 14:28:29.996500   27256 kic_runner.go:93] Run: chown docker:docker /home/docker/.ssh/authorized_keys
I0918 14:28:29.996500   27256 kic_runner.go:114] Args: [docker exec --privileged minikube chown docker:docker /home/docker/.ssh/authorized_keys]
I0918 14:28:30.198336   27256 kic.go:250] ensuring only current user has permissions to key file located at : C:\Users\ccheetham\.minikube\machines\minikube\id_rsa...
I0918 14:28:30.900499   27256 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0918 14:28:31.039044   27256 machine.go:88] provisioning docker machine ...
I0918 14:28:31.039044   27256 ubuntu.go:169] provisioning hostname "minikube"
I0918 14:28:31.046876   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:31.180584   27256 main.go:134] libmachine: Using SSH client type: native
I0918 14:28:31.185258   27256 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x453da0] 0x456c00 <nil>  [] 0s} 127.0.0.1 55225 <nil> <nil>}
I0918 14:28:31.185258   27256 main.go:134] libmachine: About to run SSH command:
sudo hostname minikube && echo "minikube" | sudo tee /etc/hostname
I0918 14:28:31.273263   27256 main.go:134] libmachine: SSH cmd err, output: <nil>: minikube

I0918 14:28:31.280677   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:31.427925   27256 main.go:134] libmachine: Using SSH client type: native
I0918 14:28:31.428476   27256 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x453da0] 0x456c00 <nil>  [] 0s} 127.0.0.1 55225 <nil> <nil>}
I0918 14:28:31.428476   27256 main.go:134] libmachine: About to run SSH command:

		if ! grep -xq '.*\sminikube' /etc/hosts; then
			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 minikube/g' /etc/hosts;
			else 
				echo '127.0.1.1 minikube' | sudo tee -a /etc/hosts; 
			fi
		fi
I0918 14:28:31.496984   27256 main.go:134] libmachine: SSH cmd err, output: <nil>: 
I0918 14:28:31.497508   27256 ubuntu.go:175] set auth options {CertDir:C:\Users\ccheetham\.minikube CaCertPath:C:\Users\ccheetham\.minikube\certs\ca.pem CaPrivateKeyPath:C:\Users\ccheetham\.minikube\certs\ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:C:\Users\ccheetham\.minikube\machines\server.pem ServerKeyPath:C:\Users\ccheetham\.minikube\machines\server-key.pem ClientKeyPath:C:\Users\ccheetham\.minikube\certs\key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:C:\Users\ccheetham\.minikube\certs\cert.pem ServerCertSANs:[] StorePath:C:\Users\ccheetham\.minikube}
I0918 14:28:31.497508   27256 ubuntu.go:177] setting up certificates
I0918 14:28:31.497508   27256 provision.go:83] configureAuth start
I0918 14:28:31.504901   27256 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0918 14:28:31.639966   27256 provision.go:138] copyHostCerts
I0918 14:28:31.639966   27256 exec_runner.go:144] found C:\Users\ccheetham\.minikube/ca.pem, removing ...
I0918 14:28:31.639966   27256 exec_runner.go:207] rm: C:\Users\ccheetham\.minikube\ca.pem
I0918 14:28:31.640471   27256 exec_runner.go:151] cp: C:\Users\ccheetham\.minikube\certs\ca.pem --> C:\Users\ccheetham\.minikube/ca.pem (1086 bytes)
I0918 14:28:31.640992   27256 exec_runner.go:144] found C:\Users\ccheetham\.minikube/cert.pem, removing ...
I0918 14:28:31.640992   27256 exec_runner.go:207] rm: C:\Users\ccheetham\.minikube\cert.pem
I0918 14:28:31.641545   27256 exec_runner.go:151] cp: C:\Users\ccheetham\.minikube\certs\cert.pem --> C:\Users\ccheetham\.minikube/cert.pem (1131 bytes)
I0918 14:28:31.642062   27256 exec_runner.go:144] found C:\Users\ccheetham\.minikube/key.pem, removing ...
I0918 14:28:31.642062   27256 exec_runner.go:207] rm: C:\Users\ccheetham\.minikube\key.pem
I0918 14:28:31.642062   27256 exec_runner.go:151] cp: C:\Users\ccheetham\.minikube\certs\key.pem --> C:\Users\ccheetham\.minikube/key.pem (1679 bytes)
I0918 14:28:31.642589   27256 provision.go:112] generating server cert: C:\Users\ccheetham\.minikube\machines\server.pem ca-key=C:\Users\ccheetham\.minikube\certs\ca.pem private-key=C:\Users\ccheetham\.minikube\certs\ca-key.pem org=ccheetham.minikube san=[192.168.49.2 127.0.0.1 localhost 127.0.0.1 minikube minikube]
I0918 14:28:31.697315   27256 provision.go:172] copyRemoteCerts
I0918 14:28:31.709271   27256 ssh_runner.go:195] Run: sudo mkdir -p /etc/docker /etc/docker /etc/docker
I0918 14:28:31.715274   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:31.856749   27256 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55225 SSHKeyPath:C:\Users\ccheetham\.minikube\machines\minikube\id_rsa Username:docker}
I0918 14:28:31.901172   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\certs\ca.pem --> /etc/docker/ca.pem (1086 bytes)
I0918 14:28:31.921255   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\machines\server.pem --> /etc/docker/server.pem (1208 bytes)
I0918 14:28:31.940462   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\machines\server-key.pem --> /etc/docker/server-key.pem (1675 bytes)
I0918 14:28:31.961533   27256 provision.go:86] duration metric: configureAuth took 464.0251ms
I0918 14:28:31.961533   27256 ubuntu.go:193] setting minikube options for container-runtime
I0918 14:28:31.962086   27256 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0918 14:28:31.969023   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:32.106241   27256 main.go:134] libmachine: Using SSH client type: native
I0918 14:28:32.106241   27256 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x453da0] 0x456c00 <nil>  [] 0s} 127.0.0.1 55225 <nil> <nil>}
I0918 14:28:32.106241   27256 main.go:134] libmachine: About to run SSH command:
df --output=fstype / | tail -n 1
I0918 14:28:32.229399   27256 main.go:134] libmachine: SSH cmd err, output: <nil>: overlay

I0918 14:28:32.229399   27256 ubuntu.go:71] root file system type: overlay
I0918 14:28:32.229399   27256 provision.go:309] Updating docker unit: /lib/systemd/system/docker.service ...
I0918 14:28:32.236234   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:32.369348   27256 main.go:134] libmachine: Using SSH client type: native
I0918 14:28:32.369348   27256 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x453da0] 0x456c00 <nil>  [] 0s} 127.0.0.1 55225 <nil> <nil>}
I0918 14:28:32.369348   27256 main.go:134] libmachine: About to run SSH command:
sudo mkdir -p /lib/systemd/system && printf %!s(MISSING) "[Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP \$MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target
" | sudo tee /lib/systemd/system/docker.service.new
I0918 14:28:32.445774   27256 main.go:134] libmachine: SSH cmd err, output: <nil>: [Unit]
Description=Docker Application Container Engine
Documentation=https://docs.docker.com
BindsTo=containerd.service
After=network-online.target firewalld.service containerd.service
Wants=network-online.target
Requires=docker.socket
StartLimitBurst=3
StartLimitIntervalSec=60

[Service]
Type=notify
Restart=on-failure



# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
# The base configuration already specifies an 'ExecStart=...' command. The first directive
# here is to clear out that command inherited from the base configuration. Without this,
# the command from the base configuration and the command specified here are treated as
# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
# will catch this invalid input and refuse to start the service with an error like:
#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.

# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
ExecStart=
ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
ExecReload=/bin/kill -s HUP $MAINPID

# Having non-zero Limit*s causes performance problems due to accounting overhead
# in the kernel. We recommend using cgroups to do container-local accounting.
LimitNOFILE=infinity
LimitNPROC=infinity
LimitCORE=infinity

# Uncomment TasksMax if your systemd version supports it.
# Only systemd 226 and above support this version.
TasksMax=infinity
TimeoutStartSec=0

# set delegate yes so that systemd does not reset the cgroups of docker containers
Delegate=yes

# kill only the docker process, not all processes in the cgroup
KillMode=process

[Install]
WantedBy=multi-user.target

I0918 14:28:32.452547   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:32.583241   27256 main.go:134] libmachine: Using SSH client type: native
I0918 14:28:32.583759   27256 main.go:134] libmachine: &{{{<nil> 0 [] [] []} docker [0x453da0] 0x456c00 <nil>  [] 0s} 127.0.0.1 55225 <nil> <nil>}
I0918 14:28:32.583759   27256 main.go:134] libmachine: About to run SSH command:
sudo diff -u /lib/systemd/system/docker.service /lib/systemd/system/docker.service.new || { sudo mv /lib/systemd/system/docker.service.new /lib/systemd/system/docker.service; sudo systemctl -f daemon-reload && sudo systemctl -f enable docker && sudo systemctl -f restart docker; }
I0918 14:28:33.276021   27256 main.go:134] libmachine: SSH cmd err, output: <nil>: --- /lib/systemd/system/docker.service	2022-06-06 23:01:03.000000000 +0000
+++ /lib/systemd/system/docker.service.new	2022-09-18 18:28:32.442536000 +0000
@@ -1,30 +1,32 @@
 [Unit]
 Description=Docker Application Container Engine
 Documentation=https://docs.docker.com
-After=network-online.target docker.socket firewalld.service containerd.service
+BindsTo=containerd.service
+After=network-online.target firewalld.service containerd.service
 Wants=network-online.target
-Requires=docker.socket containerd.service
+Requires=docker.socket
+StartLimitBurst=3
+StartLimitIntervalSec=60
 
 [Service]
 Type=notify
-# the default is not to use systemd for cgroups because the delegate issues still
-# exists and systemd currently does not support the cgroup feature set required
-# for containers run by docker
-ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock
-ExecReload=/bin/kill -s HUP $MAINPID
-TimeoutSec=0
-RestartSec=2
-Restart=always
-
-# Note that StartLimit* options were moved from "Service" to "Unit" in systemd 229.
-# Both the old, and new location are accepted by systemd 229 and up, so using the old location
-# to make them work for either version of systemd.
-StartLimitBurst=3
+Restart=on-failure
 
-# Note that StartLimitInterval was renamed to StartLimitIntervalSec in systemd 230.
-# Both the old, and new name are accepted by systemd 230 and up, so using the old name to make
-# this option work for either version of systemd.
-StartLimitInterval=60s
+
+
+# This file is a systemd drop-in unit that inherits from the base dockerd configuration.
+# The base configuration already specifies an 'ExecStart=...' command. The first directive
+# here is to clear out that command inherited from the base configuration. Without this,
+# the command from the base configuration and the command specified here are treated as
+# a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
+# will catch this invalid input and refuse to start the service with an error like:
+#  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
+
+# NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
+# container runtimes. If left unlimited, it may result in OOM issues with MySQL.
+ExecStart=
+ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=docker --insecure-registry 10.96.0.0/12 
+ExecReload=/bin/kill -s HUP $MAINPID
 
 # Having non-zero Limit*s causes performance problems due to accounting overhead
 # in the kernel. We recommend using cgroups to do container-local accounting.
@@ -32,16 +34,16 @@
 LimitNPROC=infinity
 LimitCORE=infinity
 
-# Comment TasksMax if your systemd version does not support it.
-# Only systemd 226 and above support this option.
+# Uncomment TasksMax if your systemd version supports it.
+# Only systemd 226 and above support this version.
 TasksMax=infinity
+TimeoutStartSec=0
 
 # set delegate yes so that systemd does not reset the cgroups of docker containers
 Delegate=yes
 
 # kill only the docker process, not all processes in the cgroup
 KillMode=process
-OOMScoreAdjust=-500
 
 [Install]
 WantedBy=multi-user.target
Synchronizing state of docker.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable docker

I0918 14:28:33.276021   27256 machine.go:91] provisioned docker machine in 2.2369773s
I0918 14:28:33.276533   27256 client.go:171] LocalClient.Create took 19.0245583s
I0918 14:28:33.276533   27256 start.go:174] duration metric: libmachine.API.Create for "minikube" took 19.0245583s
I0918 14:28:33.276533   27256 start.go:307] post-start starting for "minikube" (driver="docker")
I0918 14:28:33.276533   27256 start.go:335] creating required directories: [/etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs]
I0918 14:28:33.289518   27256 ssh_runner.go:195] Run: sudo mkdir -p /etc/kubernetes/addons /etc/kubernetes/manifests /var/tmp/minikube /var/lib/minikube /var/lib/minikube/certs /var/lib/minikube/images /var/lib/minikube/binaries /tmp/gvisor /usr/share/ca-certificates /etc/ssl/certs
I0918 14:28:33.296291   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:33.438710   27256 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55225 SSHKeyPath:C:\Users\ccheetham\.minikube\machines\minikube\id_rsa Username:docker}
I0918 14:28:33.533561   27256 ssh_runner.go:195] Run: cat /etc/os-release
I0918 14:28:33.537724   27256 main.go:134] libmachine: Couldn't set key PRIVACY_POLICY_URL, no corresponding struct field found
I0918 14:28:33.537724   27256 main.go:134] libmachine: Couldn't set key VERSION_CODENAME, no corresponding struct field found
I0918 14:28:33.537724   27256 main.go:134] libmachine: Couldn't set key UBUNTU_CODENAME, no corresponding struct field found
I0918 14:28:33.537724   27256 info.go:137] Remote host: Ubuntu 20.04.4 LTS
I0918 14:28:33.537724   27256 filesync.go:126] Scanning C:\Users\ccheetham\.minikube\addons for local assets ...
I0918 14:28:33.537724   27256 filesync.go:126] Scanning C:\Users\ccheetham\.minikube\files for local assets ...
I0918 14:28:33.537724   27256 start.go:310] post-start completed in 261.1906ms
I0918 14:28:33.545712   27256 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0918 14:28:33.685063   27256 profile.go:148] Saving config to C:\Users\ccheetham\.minikube\profiles\minikube\config.json ...
I0918 14:28:33.698106   27256 ssh_runner.go:195] Run: sh -c "df -h /var | awk 'NR==2{print $5}'"
I0918 14:28:33.706571   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:33.838548   27256 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55225 SSHKeyPath:C:\Users\ccheetham\.minikube\machines\minikube\id_rsa Username:docker}
I0918 14:28:33.929958   27256 ssh_runner.go:195] Run: sh -c "df -BG /var | awk 'NR==2{print $4}'"
I0918 14:28:33.935113   27256 start.go:135] duration metric: createHost completed in 19.6862619s
I0918 14:28:33.935113   27256 start.go:82] releasing machines lock for "minikube", held for 19.6868045s
I0918 14:28:33.941992   27256 cli_runner.go:164] Run: docker container inspect -f "{{range .NetworkSettings.Networks}}{{.IPAddress}},{{.GlobalIPv6Address}}{{end}}" minikube
I0918 14:28:34.072440   27256 ssh_runner.go:195] Run: curl -sS -m 2 https://k8s.gcr.io/
I0918 14:28:34.080162   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:34.082942   27256 ssh_runner.go:195] Run: systemctl --version
I0918 14:28:34.089409   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:34.224833   27256 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55225 SSHKeyPath:C:\Users\ccheetham\.minikube\machines\minikube\id_rsa Username:docker}
I0918 14:28:34.235955   27256 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55225 SSHKeyPath:C:\Users\ccheetham\.minikube\machines\minikube\id_rsa Username:docker}
I0918 14:28:34.566587   27256 ssh_runner.go:195] Run: sudo systemctl cat docker.service
I0918 14:28:34.577095   27256 cruntime.go:273] skipping containerd shutdown because we are bound to it
I0918 14:28:34.589301   27256 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service crio
I0918 14:28:34.599931   27256 ssh_runner.go:195] Run: /bin/bash -c "sudo mkdir -p /etc && printf %!s(MISSING) "runtime-endpoint: unix:///var/run/cri-dockerd.sock
image-endpoint: unix:///var/run/cri-dockerd.sock
" | sudo tee /etc/crictl.yaml"
I0918 14:28:34.625341   27256 ssh_runner.go:195] Run: sudo systemctl unmask docker.service
I0918 14:28:34.721602   27256 ssh_runner.go:195] Run: sudo systemctl enable docker.socket
I0918 14:28:34.826334   27256 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0918 14:28:34.933158   27256 ssh_runner.go:195] Run: sudo systemctl restart docker
I0918 14:28:35.163602   27256 ssh_runner.go:195] Run: sudo systemctl enable cri-docker.socket
I0918 14:28:35.267161   27256 ssh_runner.go:195] Run: sudo systemctl daemon-reload
I0918 14:28:35.363043   27256 ssh_runner.go:195] Run: sudo systemctl start cri-docker.socket
I0918 14:28:35.377611   27256 start.go:450] Will wait 60s for socket path /var/run/cri-dockerd.sock
I0918 14:28:35.390825   27256 ssh_runner.go:195] Run: stat /var/run/cri-dockerd.sock
I0918 14:28:35.395167   27256 start.go:471] Will wait 60s for crictl version
I0918 14:28:35.406160   27256 ssh_runner.go:195] Run: sudo crictl version
I0918 14:28:35.555770   27256 start.go:480] Version:  0.1.0
RuntimeName:  docker
RuntimeVersion:  20.10.17
RuntimeApiVersion:  1.41.0
I0918 14:28:35.562107   27256 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0918 14:28:35.633287   27256 ssh_runner.go:195] Run: docker version --format {{.Server.Version}}
I0918 14:28:35.669810   27256 out.go:204] üê≥  Preparing Kubernetes v1.24.3 on Docker 20.10.17 ...
I0918 14:28:35.677890   27256 cli_runner.go:164] Run: docker exec -t minikube dig +short host.docker.internal
I0918 14:28:35.967416   27256 network.go:96] got host ip for mount in container by digging dns: 192.168.65.2
I0918 14:28:35.977803   27256 ssh_runner.go:195] Run: grep 192.168.65.2	host.minikube.internal$ /etc/hosts
I0918 14:28:35.981829   27256 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\thost.minikube.internal$' "/etc/hosts"; echo "192.168.65.2	host.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0918 14:28:35.997685   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0918 14:28:36.137552   27256 preload.go:132] Checking if preload exists for k8s version v1.24.3 and runtime docker
I0918 14:28:36.143756   27256 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0918 14:28:36.169455   27256 docker.go:611] Got preloaded images: -- stdout --
k8s.gcr.io/kube-apiserver:v1.24.3
k8s.gcr.io/kube-proxy:v1.24.3
k8s.gcr.io/kube-scheduler:v1.24.3
k8s.gcr.io/kube-controller-manager:v1.24.3
k8s.gcr.io/etcd:3.5.3-0
k8s.gcr.io/pause:3.7
k8s.gcr.io/coredns/coredns:v1.8.6
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0918 14:28:36.169455   27256 docker.go:542] Images already preloaded, skipping extraction
I0918 14:28:36.176366   27256 ssh_runner.go:195] Run: docker images --format {{.Repository}}:{{.Tag}}
I0918 14:28:36.201244   27256 docker.go:611] Got preloaded images: -- stdout --
k8s.gcr.io/kube-apiserver:v1.24.3
k8s.gcr.io/kube-scheduler:v1.24.3
k8s.gcr.io/kube-controller-manager:v1.24.3
k8s.gcr.io/kube-proxy:v1.24.3
k8s.gcr.io/etcd:3.5.3-0
k8s.gcr.io/pause:3.7
k8s.gcr.io/coredns/coredns:v1.8.6
gcr.io/k8s-minikube/storage-provisioner:v5

-- /stdout --
I0918 14:28:36.201244   27256 cache_images.go:84] Images are preloaded, skipping loading
I0918 14:28:36.208029   27256 ssh_runner.go:195] Run: docker info --format {{.CgroupDriver}}
I0918 14:28:36.429385   27256 cni.go:95] Creating CNI manager for ""
I0918 14:28:36.429385   27256 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0918 14:28:36.429911   27256 kubeadm.go:87] Using pod CIDR: 10.244.0.0/16
I0918 14:28:36.429911   27256 kubeadm.go:158] kubeadm options: {CertDir:/var/lib/minikube/certs ServiceCIDR:10.96.0.0/12 PodSubnet:10.244.0.0/16 AdvertiseAddress:192.168.49.2 APIServerPort:8443 KubernetesVersion:v1.24.3 EtcdDataDir:/var/lib/minikube/etcd EtcdExtraArgs:map[] ClusterName:minikube NodeName:minikube DNSDomain:cluster.local CRISocket:/var/run/cri-dockerd.sock ImageRepository: ComponentOptions:[{Component:apiServer ExtraArgs:map[enable-admission-plugins:NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota] Pairs:map[certSANs:["127.0.0.1", "localhost", "192.168.49.2"]]} {Component:controllerManager ExtraArgs:map[allocate-node-cidrs:true leader-elect:false] Pairs:map[]} {Component:scheduler ExtraArgs:map[leader-elect:false] Pairs:map[]}] FeatureArgs:map[] NoTaintMaster:true NodeIP:192.168.49.2 CgroupDriver:cgroupfs ClientCAFile:/var/lib/minikube/certs/ca.crt StaticPodPath:/etc/kubernetes/manifests ControlPlaneAddress:control-plane.minikube.internal KubeProxyOptions:map[]}
I0918 14:28:36.429911   27256 kubeadm.go:162] kubeadm config:
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 192.168.49.2
  bindPort: 8443
bootstrapTokens:
  - groups:
      - system:bootstrappers:kubeadm:default-node-token
    ttl: 24h0m0s
    usages:
      - signing
      - authentication
nodeRegistration:
  criSocket: /var/run/cri-dockerd.sock
  name: "minikube"
  kubeletExtraArgs:
    node-ip: 192.168.49.2
  taints: []
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
apiServer:
  certSANs: ["127.0.0.1", "localhost", "192.168.49.2"]
  extraArgs:
    enable-admission-plugins: "NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,NodeRestriction,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota"
controllerManager:
  extraArgs:
    allocate-node-cidrs: "true"
    leader-elect: "false"
scheduler:
  extraArgs:
    leader-elect: "false"
certificatesDir: /var/lib/minikube/certs
clusterName: mk
controlPlaneEndpoint: control-plane.minikube.internal:8443
etcd:
  local:
    dataDir: /var/lib/minikube/etcd
    extraArgs:
      proxy-refresh-interval: "70000"
kubernetesVersion: v1.24.3
networking:
  dnsDomain: cluster.local
  podSubnet: "10.244.0.0/16"
  serviceSubnet: 10.96.0.0/12
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
authentication:
  x509:
    clientCAFile: /var/lib/minikube/certs/ca.crt
cgroupDriver: cgroupfs
clusterDomain: "cluster.local"
# disable disk resource management by default
imageGCHighThresholdPercent: 100
evictionHard:
  nodefs.available: "0%!"(MISSING)
  nodefs.inodesFree: "0%!"(MISSING)
  imagefs.available: "0%!"(MISSING)
failSwapOn: false
staticPodPath: /etc/kubernetes/manifests
---
apiVersion: kubeproxy.config.k8s.io/v1alpha1
kind: KubeProxyConfiguration
clusterCIDR: "10.244.0.0/16"
metricsBindAddress: 0.0.0.0:10249
conntrack:
  maxPerCore: 0
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_established"
  tcpEstablishedTimeout: 0s
# Skip setting "net.netfilter.nf_conntrack_tcp_timeout_close"
  tcpCloseWaitTimeout: 0s

I0918 14:28:36.430443   27256 kubeadm.go:961] kubelet [Unit]
Wants=docker.socket

[Service]
ExecStart=
ExecStart=/var/lib/minikube/binaries/v1.24.3/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/cri-dockerd.sock --hostname-override=minikube --image-service-endpoint=/var/run/cri-dockerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.49.2 --runtime-request-timeout=15m

[Install]
 config:
{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:}
I0918 14:28:36.442001   27256 ssh_runner.go:195] Run: sudo ls /var/lib/minikube/binaries/v1.24.3
I0918 14:28:36.450036   27256 binaries.go:44] Found k8s binaries, skipping transfer
I0918 14:28:36.463731   27256 ssh_runner.go:195] Run: sudo mkdir -p /etc/systemd/system/kubelet.service.d /lib/systemd/system /var/tmp/minikube
I0918 14:28:36.471628   27256 ssh_runner.go:362] scp memory --> /etc/systemd/system/kubelet.service.d/10-kubeadm.conf (470 bytes)
I0918 14:28:36.484213   27256 ssh_runner.go:362] scp memory --> /lib/systemd/system/kubelet.service (352 bytes)
I0918 14:28:36.496870   27256 ssh_runner.go:362] scp memory --> /var/tmp/minikube/kubeadm.yaml.new (2031 bytes)
I0918 14:28:36.519910   27256 ssh_runner.go:195] Run: grep 192.168.49.2	control-plane.minikube.internal$ /etc/hosts
I0918 14:28:36.523791   27256 ssh_runner.go:195] Run: /bin/bash -c "{ grep -v $'\tcontrol-plane.minikube.internal$' "/etc/hosts"; echo "192.168.49.2	control-plane.minikube.internal"; } > /tmp/h.$$; sudo cp /tmp/h.$$ "/etc/hosts""
I0918 14:28:36.532735   27256 certs.go:54] Setting up C:\Users\ccheetham\.minikube\profiles\minikube for IP: 192.168.49.2
I0918 14:28:36.533259   27256 certs.go:182] skipping minikubeCA CA generation: C:\Users\ccheetham\.minikube\ca.key
I0918 14:28:36.533779   27256 certs.go:182] skipping proxyClientCA CA generation: C:\Users\ccheetham\.minikube\proxy-client-ca.key
I0918 14:28:36.533779   27256 certs.go:302] generating minikube-user signed cert: C:\Users\ccheetham\.minikube\profiles\minikube\client.key
I0918 14:28:36.534299   27256 crypto.go:68] Generating cert C:\Users\ccheetham\.minikube\profiles\minikube\client.crt with IP's: []
I0918 14:28:36.606552   27256 crypto.go:156] Writing cert to C:\Users\ccheetham\.minikube\profiles\minikube\client.crt ...
I0918 14:28:36.606552   27256 lock.go:35] WriteFile acquiring C:\Users\ccheetham\.minikube\profiles\minikube\client.crt: {Name:mkf7de9e6e1849fae54b6af4a274f0baf890b94b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0918 14:28:36.607543   27256 crypto.go:164] Writing key to C:\Users\ccheetham\.minikube\profiles\minikube\client.key ...
I0918 14:28:36.607543   27256 lock.go:35] WriteFile acquiring C:\Users\ccheetham\.minikube\profiles\minikube\client.key: {Name:mk650a8632fad33f7c2b19a45ba2a35d88ffb6f7 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0918 14:28:36.608542   27256 certs.go:302] generating minikube signed cert: C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.key.dd3b5fb2
I0918 14:28:36.610542   27256 crypto.go:68] Generating cert C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2 with IP's: [192.168.49.2 10.96.0.1 127.0.0.1 10.0.0.1]
I0918 14:28:36.690540   27256 crypto.go:156] Writing cert to C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2 ...
I0918 14:28:36.690540   27256 lock.go:35] WriteFile acquiring C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2: {Name:mka37fe949c8a728a92f9f65190b13f53209c378 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0918 14:28:36.690540   27256 crypto.go:164] Writing key to C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.key.dd3b5fb2 ...
I0918 14:28:36.690540   27256 lock.go:35] WriteFile acquiring C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.key.dd3b5fb2: {Name:mk2c831c91dcc23cc979ea76ddb29dc084ad0d10 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0918 14:28:36.691551   27256 certs.go:320] copying C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.crt.dd3b5fb2 -> C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.crt
I0918 14:28:36.695540   27256 certs.go:324] copying C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.key.dd3b5fb2 -> C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.key
I0918 14:28:36.695540   27256 certs.go:302] generating aggregator signed cert: C:\Users\ccheetham\.minikube\profiles\minikube\proxy-client.key
I0918 14:28:36.696539   27256 crypto.go:68] Generating cert C:\Users\ccheetham\.minikube\profiles\minikube\proxy-client.crt with IP's: []
I0918 14:28:36.891594   27256 crypto.go:156] Writing cert to C:\Users\ccheetham\.minikube\profiles\minikube\proxy-client.crt ...
I0918 14:28:36.891594   27256 lock.go:35] WriteFile acquiring C:\Users\ccheetham\.minikube\profiles\minikube\proxy-client.crt: {Name:mk5683f753cd03be22247714cf00d282f97f7b9d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0918 14:28:36.892602   27256 crypto.go:164] Writing key to C:\Users\ccheetham\.minikube\profiles\minikube\proxy-client.key ...
I0918 14:28:36.892602   27256 lock.go:35] WriteFile acquiring C:\Users\ccheetham\.minikube\profiles\minikube\proxy-client.key: {Name:mka95ed104288d1d532e3325c2d4718b29eba162 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0918 14:28:36.896595   27256 certs.go:388] found cert: C:\Users\ccheetham\.minikube\certs\C:\Users\ccheetham\.minikube\certs\ca-key.pem (1679 bytes)
I0918 14:28:36.896595   27256 certs.go:388] found cert: C:\Users\ccheetham\.minikube\certs\C:\Users\ccheetham\.minikube\certs\ca.pem (1086 bytes)
I0918 14:28:36.896595   27256 certs.go:388] found cert: C:\Users\ccheetham\.minikube\certs\C:\Users\ccheetham\.minikube\certs\cert.pem (1131 bytes)
I0918 14:28:36.896595   27256 certs.go:388] found cert: C:\Users\ccheetham\.minikube\certs\C:\Users\ccheetham\.minikube\certs\key.pem (1679 bytes)
I0918 14:28:36.897595   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.crt --> /var/lib/minikube/certs/apiserver.crt (1399 bytes)
I0918 14:28:36.917143   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\profiles\minikube\apiserver.key --> /var/lib/minikube/certs/apiserver.key (1675 bytes)
I0918 14:28:36.934581   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\profiles\minikube\proxy-client.crt --> /var/lib/minikube/certs/proxy-client.crt (1147 bytes)
I0918 14:28:36.951892   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\profiles\minikube\proxy-client.key --> /var/lib/minikube/certs/proxy-client.key (1675 bytes)
I0918 14:28:36.968603   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\ca.crt --> /var/lib/minikube/certs/ca.crt (1111 bytes)
I0918 14:28:36.985890   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\ca.key --> /var/lib/minikube/certs/ca.key (1679 bytes)
I0918 14:28:37.002795   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\proxy-client-ca.crt --> /var/lib/minikube/certs/proxy-client-ca.crt (1119 bytes)
I0918 14:28:37.020068   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\proxy-client-ca.key --> /var/lib/minikube/certs/proxy-client-ca.key (1679 bytes)
I0918 14:28:37.037493   27256 ssh_runner.go:362] scp C:\Users\ccheetham\.minikube\ca.crt --> /usr/share/ca-certificates/minikubeCA.pem (1111 bytes)
I0918 14:28:37.054835   27256 ssh_runner.go:362] scp memory --> /var/lib/minikube/kubeconfig (738 bytes)
I0918 14:28:37.077275   27256 ssh_runner.go:195] Run: openssl version
I0918 14:28:37.094626   27256 ssh_runner.go:195] Run: sudo /bin/bash -c "test -s /usr/share/ca-certificates/minikubeCA.pem && ln -fs /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem"
I0918 14:28:37.118361   27256 ssh_runner.go:195] Run: ls -la /usr/share/ca-certificates/minikubeCA.pem
I0918 14:28:37.122782   27256 certs.go:431] hashing: -rw-r--r-- 1 root root 1111 Sep 12 15:58 /usr/share/ca-certificates/minikubeCA.pem
I0918 14:28:37.133895   27256 ssh_runner.go:195] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
I0918 14:28:37.150248   27256 ssh_runner.go:195] Run: sudo /bin/bash -c "test -L /etc/ssl/certs/b5213941.0 || ln -fs /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0"
I0918 14:28:37.159254   27256 kubeadm.go:395] StartCluster: {Name:minikube KeepContext:false EmbedCerts:false MinikubeISO: KicBaseImage:gcr.io/k8s-minikube/kicbase:v0.0.33@sha256:73b259e144d926189cf169ae5b46bbec4e08e4e2f2bd87296054c3244f70feb8 Memory:8192 CPUs:8 DiskSize:12288 VMDriver: Driver:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] ContainerVolumeMounts:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.59.1/24 HypervVirtualSwitch: HypervUseExternalSwitch:false HypervExternalAdapter: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false KVMNUMACount:1 APIServerPort:0 DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true HostOnlyNicType:virtio NatNicType:virtio SSHIPAddress: SSHUser:root SSHKey: SSHPort:22 KubernetesConfig:{KubernetesVersion:v1.24.3 ClusterName:minikube Namespace:default APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: LoadBalancerStartIP: LoadBalancerEndIP: CustomIngressCert: RegistryAliases: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false CNI: NodeIP: NodePort:8443 NodeName:} Nodes:[{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}] Addons:map[] CustomAddonImages:map[] CustomAddonRegistries:map[] VerifyComponents:map[apiserver:true system_pods:true] StartHostTimeout:6m0s ScheduledStop:<nil> ExposedPorts:[] ListenAddress: Network: Subnet: MultiNodeRequested:false ExtraDisks:0 CertExpiration:26280h0m0s Mount:false MountString:C:\Users\ccheetham:/minikube-host Mount9PVersion:9p2000.L MountGID:docker MountIP: MountMSize:262144 MountOptions:[] MountPort:0 MountType:9p MountUID:docker BinaryMirror: DisableOptimizations:false DisableMetrics:false CustomQemuFirmwarePath:}
I0918 14:28:37.165729   27256 ssh_runner.go:195] Run: docker ps --filter status=paused --filter=name=k8s_.*_(kube-system)_ --format={{.ID}}
I0918 14:28:37.202201   27256 ssh_runner.go:195] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
I0918 14:28:37.221155   27256 ssh_runner.go:195] Run: sudo cp /var/tmp/minikube/kubeadm.yaml.new /var/tmp/minikube/kubeadm.yaml
I0918 14:28:37.229656   27256 kubeadm.go:221] ignoring SystemVerification for kubeadm because of docker driver
I0918 14:28:37.240753   27256 ssh_runner.go:195] Run: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf
I0918 14:28:37.248504   27256 kubeadm.go:152] config check failed, skipping stale config cleanup: sudo ls -la /etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf: Process exited with status 2
stdout:

stderr:
ls: cannot access '/etc/kubernetes/admin.conf': No such file or directory
ls: cannot access '/etc/kubernetes/kubelet.conf': No such file or directory
ls: cannot access '/etc/kubernetes/controller-manager.conf': No such file or directory
ls: cannot access '/etc/kubernetes/scheduler.conf': No such file or directory
I0918 14:28:37.249026   27256 ssh_runner.go:286] Start: /bin/bash -c "sudo env PATH="/var/lib/minikube/binaries/v1.24.3:$PATH" kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap,Mem,SystemVerification,FileContent--proc-sys-net-bridge-bridge-nf-call-iptables"
I0918 14:28:50.561486   27256 out.go:204]     ‚ñ™ Generating certificates and keys ...
I0918 14:28:50.565486   27256 out.go:204]     ‚ñ™ Booting up control plane ...
I0918 14:28:50.568486   27256 out.go:204]     ‚ñ™ Configuring RBAC rules ...
I0918 14:28:50.571487   27256 cni.go:95] Creating CNI manager for ""
I0918 14:28:50.571487   27256 cni.go:169] CNI unnecessary in this configuration, recommending no CNI
I0918 14:28:50.571487   27256 ssh_runner.go:195] Run: /bin/bash -c "cat /proc/$(pgrep kube-apiserver)/oom_adj"
I0918 14:28:50.579697   27256 ops.go:34] apiserver oom_adj: -16
I0918 14:28:50.588756   27256 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.24.3/kubectl label nodes minikube.k8s.io/version=v1.26.1 minikube.k8s.io/commit=62e108c3dfdec8029a890ad6d8ef96b6461426dc minikube.k8s.io/name=minikube minikube.k8s.io/updated_at=2022_09_18T14_28_50_0700 minikube.k8s.io/primary=true --all --overwrite --kubeconfig=/var/lib/minikube/kubeconfig
I0918 14:28:50.588756   27256 ssh_runner.go:195] Run: sudo /var/lib/minikube/binaries/v1.24.3/kubectl create clusterrolebinding minikube-rbac --clusterrole=cluster-admin --serviceaccount=kube-system:default --kubeconfig=/var/lib/minikube/kubeconfig
I0918 14:28:50.652714   27256 kubeadm.go:1045] duration metric: took 81.2266ms to wait for elevateKubeSystemPrivileges.
I0918 14:28:50.983377   27256 kubeadm.go:397] StartCluster complete in 13.8246583s
I0918 14:28:50.983377   27256 settings.go:142] acquiring lock: {Name:mk5bfc850ae4282ba737cd2dfe15a12b3d78bdfc Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0918 14:28:50.983377   27256 settings.go:150] Updating kubeconfig:  C:\Users\ccheetham\.kube\config
I0918 14:28:50.985489   27256 lock.go:35] WriteFile acquiring C:\Users\ccheetham\.kube\config: {Name:mkf3cfb433f301958a34623466ea787f7a4d957f Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
I0918 14:28:51.514837   27256 kapi.go:244] deployment "coredns" in namespace "kube-system" and context "minikube" rescaled to 1
I0918 14:28:51.514837   27256 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml"
I0918 14:28:51.514837   27256 start.go:211] Will wait 6m0s for node &{Name: IP:192.168.49.2 Port:8443 KubernetesVersion:v1.24.3 ContainerRuntime:docker ControlPlane:true Worker:true}
I0918 14:28:51.515366   27256 addons.go:412] enableAddons start: toEnable=map[], additional=[]
I0918 14:28:51.516970   27256 out.go:177] üîé  Verifying Kubernetes components...
I0918 14:28:51.515366   27256 config.go:180] Loaded profile config "minikube": Driver=docker, ContainerRuntime=docker, KubernetesVersion=v1.24.3
I0918 14:28:51.516970   27256 addons.go:65] Setting default-storageclass=true in profile "minikube"
I0918 14:28:51.516970   27256 addons.go:65] Setting storage-provisioner=true in profile "minikube"
I0918 14:28:51.518558   27256 addons_storage_classes.go:33] enableOrDisableStorageClasses default-storageclass=true on "minikube"
I0918 14:28:51.518558   27256 addons.go:153] Setting addon storage-provisioner=true in "minikube"
W0918 14:28:51.520153   27256 addons.go:162] addon storage-provisioner should already be in state true
I0918 14:28:51.520681   27256 host.go:66] Checking if "minikube" exists ...
I0918 14:28:51.534013   27256 ssh_runner.go:195] Run: sudo systemctl is-active --quiet service kubelet
I0918 14:28:51.538490   27256 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0918 14:28:51.539012   27256 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0918 14:28:51.578051   27256 ssh_runner.go:195] Run: /bin/bash -c "sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig -n kube-system get configmap coredns -o yaml | sed '/^        forward . \/etc\/resolv.conf.*/i \        hosts {\n           192.168.65.2 host.minikube.internal\n           fallthrough\n        }' | sudo /var/lib/minikube/binaries/v1.24.3/kubectl --kubeconfig=/var/lib/minikube/kubeconfig replace -f -"
I0918 14:28:51.588277   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "8443/tcp") 0).HostPort}}'" minikube
I0918 14:28:51.716626   27256 addons.go:153] Setting addon default-storageclass=true in "minikube"
W0918 14:28:51.716626   27256 addons.go:162] addon default-storageclass should already be in state true
I0918 14:28:51.716626   27256 host.go:66] Checking if "minikube" exists ...
I0918 14:28:51.728627   27256 out.go:177]     ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
I0918 14:28:51.730626   27256 addons.go:345] installing /etc/kubernetes/addons/storage-provisioner.yaml
I0918 14:28:51.730626   27256 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storage-provisioner.yaml (2676 bytes)
I0918 14:28:51.730626   27256 cli_runner.go:164] Run: docker container inspect minikube --format={{.State.Status}}
I0918 14:28:51.738626   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:51.742626   27256 api_server.go:51] waiting for apiserver process to appear ...
I0918 14:28:51.757625   27256 ssh_runner.go:195] Run: sudo pgrep -xnf kube-apiserver.*minikube.*
I0918 14:28:51.884728   27256 addons.go:345] installing /etc/kubernetes/addons/storageclass.yaml
I0918 14:28:51.884728   27256 ssh_runner.go:362] scp memory --> /etc/kubernetes/addons/storageclass.yaml (271 bytes)
I0918 14:28:51.892656   27256 cli_runner.go:164] Run: docker container inspect -f "'{{(index (index .NetworkSettings.Ports "22/tcp") 0).HostPort}}'" minikube
I0918 14:28:51.895300   27256 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55225 SSHKeyPath:C:\Users\ccheetham\.minikube\machines\minikube\id_rsa Username:docker}
I0918 14:28:51.954128   27256 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.24.3/kubectl apply -f /etc/kubernetes/addons/storage-provisioner.yaml
I0918 14:28:52.039212   27256 sshutil.go:53] new ssh client: &{IP:127.0.0.1 Port:55225 SSHKeyPath:C:\Users\ccheetham\.minikube\machines\minikube\id_rsa Username:docker}
I0918 14:28:52.132757   27256 start.go:809] {"host.minikube.internal": 192.168.65.2} host record injected into CoreDNS
I0918 14:28:52.132757   27256 api_server.go:71] duration metric: took 617.9201ms to wait for apiserver process to appear ...
I0918 14:28:52.132757   27256 api_server.go:87] waiting for apiserver healthz status ...
I0918 14:28:52.132757   27256 api_server.go:240] Checking apiserver healthz at https://127.0.0.1:55229/healthz ...
I0918 14:28:52.140755   27256 api_server.go:266] https://127.0.0.1:55229/healthz returned 200:
ok
I0918 14:28:52.142878   27256 api_server.go:140] control plane version: v1.24.3
I0918 14:28:52.142878   27256 api_server.go:130] duration metric: took 10.1209ms to wait for apiserver health ...
I0918 14:28:52.142878   27256 system_pods.go:43] waiting for kube-system pods to appear ...
I0918 14:28:52.150825   27256 system_pods.go:59] 4 kube-system pods found
I0918 14:28:52.150825   27256 system_pods.go:61] "etcd-minikube" [b7d496c0-6fea-400e-b56c-b5e5eb51ecb4] Pending
I0918 14:28:52.150825   27256 system_pods.go:61] "kube-apiserver-minikube" [38546bc2-b44d-48b6-b7a8-444206b08801] Running / Ready:ContainersNotReady (containers with unready status: [kube-apiserver]) / ContainersReady:ContainersNotReady (containers with unready status: [kube-apiserver])
I0918 14:28:52.150825   27256 system_pods.go:61] "kube-controller-manager-minikube" [6a502db1-e1b0-4342-a30a-da454d0fc27d] Pending
I0918 14:28:52.150825   27256 system_pods.go:61] "kube-scheduler-minikube" [9f2df0e2-7e78-4e61-8a62-da0eb909f5f5] Pending
I0918 14:28:52.150825   27256 system_pods.go:74] duration metric: took 7.9473ms to wait for pod list to return data ...
I0918 14:28:52.150825   27256 kubeadm.go:572] duration metric: took 635.9883ms to wait for : map[apiserver:true system_pods:true] ...
I0918 14:28:52.150825   27256 node_conditions.go:102] verifying NodePressure condition ...
I0918 14:28:52.154521   27256 ssh_runner.go:195] Run: sudo KUBECONFIG=/var/lib/minikube/kubeconfig /var/lib/minikube/binaries/v1.24.3/kubectl apply -f /etc/kubernetes/addons/storageclass.yaml
I0918 14:28:52.158211   27256 node_conditions.go:122] node storage ephemeral capacity is 263174212Ki
I0918 14:28:52.158211   27256 node_conditions.go:123] node cpu capacity is 8
I0918 14:28:52.158211   27256 node_conditions.go:105] duration metric: took 7.3862ms to run NodePressure ...
I0918 14:28:52.158211   27256 start.go:216] waiting for startup goroutines ...
I0918 14:28:52.257424   27256 out.go:177] üåü  Enabled addons: storage-provisioner, default-storageclass
I0918 14:28:52.260602   27256 addons.go:414] enableAddons completed in 745.2365ms
I0918 14:28:52.382644   27256 start.go:506] kubectl: 1.25.0, cluster: 1.24.3 (minor skew: 1)
I0918 14:28:52.387343   27256 out.go:177] üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default


==> Docker <==
-- Logs begin at Sun 2022-09-18 18:28:29 UTC, end at Sun 2022-09-18 18:29:02 UTC. --
Sep 18 18:28:33 minikube dockerd[260]: time="2022-09-18T18:28:33.075051000Z" level=info msg="stopping event stream following graceful shutdown" error="context canceled" module=libcontainerd namespace=plugins.moby
Sep 18 18:28:33 minikube systemd[1]: docker.service: Succeeded.
Sep 18 18:28:33 minikube systemd[1]: Stopped Docker Application Container Engine.
Sep 18 18:28:33 minikube systemd[1]: Starting Docker Application Container Engine...
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.112225100Z" level=info msg="Starting up"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.114260900Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.114313500Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.114346000Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.114357600Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.115347700Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.115375600Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.115388200Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.115397000Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.126114100Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.136509800Z" level=warning msg="Your kernel does not support cgroup blkio weight"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.136564200Z" level=warning msg="Your kernel does not support cgroup blkio weight_device"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.136571700Z" level=warning msg="Your kernel does not support cgroup blkio throttle.read_bps_device"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.136575300Z" level=warning msg="Your kernel does not support cgroup blkio throttle.write_bps_device"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.136578900Z" level=warning msg="Your kernel does not support cgroup blkio throttle.read_iops_device"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.136582500Z" level=warning msg="Your kernel does not support cgroup blkio throttle.write_iops_device"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.136740200Z" level=info msg="Loading containers: start."
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.208772300Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.243325700Z" level=info msg="Loading containers: done."
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.254301300Z" level=info msg="Docker daemon" commit=a89b842 graphdriver(s)=overlay2 version=20.10.17
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.254360600Z" level=info msg="Daemon has completed initialization"
Sep 18 18:28:33 minikube systemd[1]: Started Docker Application Container Engine.
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.278530500Z" level=info msg="API listen on [::]:2376"
Sep 18 18:28:33 minikube dockerd[508]: time="2022-09-18T18:28:33.281257600Z" level=info msg="API listen on /var/run/docker.sock"
Sep 18 18:28:34 minikube systemd[1]: Stopping Docker Application Container Engine...
Sep 18 18:28:34 minikube dockerd[508]: time="2022-09-18T18:28:34.942087600Z" level=info msg="Processing signal 'terminated'"
Sep 18 18:28:34 minikube dockerd[508]: time="2022-09-18T18:28:34.943282900Z" level=info msg="stopping event stream following graceful shutdown" error="<nil>" module=libcontainerd namespace=moby
Sep 18 18:28:34 minikube dockerd[508]: time="2022-09-18T18:28:34.943806500Z" level=info msg="Daemon shutdown complete"
Sep 18 18:28:34 minikube dockerd[508]: time="2022-09-18T18:28:34.943999000Z" level=info msg="stopping event stream following graceful shutdown" error="context canceled" module=libcontainerd namespace=plugins.moby
Sep 18 18:28:34 minikube systemd[1]: docker.service: Succeeded.
Sep 18 18:28:34 minikube systemd[1]: Stopped Docker Application Container Engine.
Sep 18 18:28:34 minikube systemd[1]: Starting Docker Application Container Engine...
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.980374600Z" level=info msg="Starting up"
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.982305800Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.982335800Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.982352600Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.982360900Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.983240600Z" level=info msg="parsed scheme: \"unix\"" module=grpc
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.983270600Z" level=info msg="scheme \"unix\" not registered, fallback to default scheme" module=grpc
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.983283400Z" level=info msg="ccResolverWrapper: sending update to cc: {[{unix:///run/containerd/containerd.sock  <nil> 0 <nil>}] <nil> <nil>}" module=grpc
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.983290300Z" level=info msg="ClientConn switching balancer to \"pick_first\"" module=grpc
Sep 18 18:28:34 minikube dockerd[718]: time="2022-09-18T18:28:34.994838700Z" level=info msg="[graphdriver] using prior storage driver: overlay2"
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.005084300Z" level=warning msg="Your kernel does not support cgroup blkio weight"
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.005122500Z" level=warning msg="Your kernel does not support cgroup blkio weight_device"
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.005130500Z" level=warning msg="Your kernel does not support cgroup blkio throttle.read_bps_device"
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.005134200Z" level=warning msg="Your kernel does not support cgroup blkio throttle.write_bps_device"
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.005137900Z" level=warning msg="Your kernel does not support cgroup blkio throttle.read_iops_device"
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.005141300Z" level=warning msg="Your kernel does not support cgroup blkio throttle.write_iops_device"
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.005297500Z" level=info msg="Loading containers: start."
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.081280800Z" level=info msg="Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address"
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.115543400Z" level=info msg="Loading containers: done."
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.126327200Z" level=info msg="Docker daemon" commit=a89b842 graphdriver(s)=overlay2 version=20.10.17
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.126386300Z" level=info msg="Daemon has completed initialization"
Sep 18 18:28:35 minikube systemd[1]: Started Docker Application Container Engine.
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.154031000Z" level=info msg="API listen on [::]:2376"
Sep 18 18:28:35 minikube dockerd[718]: time="2022-09-18T18:28:35.156981900Z" level=info msg="API listen on /var/run/docker.sock"


==> container status <==
CONTAINER           IMAGE               CREATED             STATE               NAME                      ATTEMPT             POD ID
f63397277d97e       aebe758cef4cd       18 seconds ago      Running             etcd                      0                   28d9c741df3b9
c060873942db4       3a5aa3a515f5d       18 seconds ago      Running             kube-scheduler            0                   e790b6655af12
91fae8712e339       d521dd763e2e3       18 seconds ago      Running             kube-apiserver            0                   47562878d44db
ff691578de002       586c112956dfc       18 seconds ago      Running             kube-controller-manager   0                   7f8c2b23c8f38


==> describe nodes <==
Name:               minikube
Roles:              control-plane
Labels:             beta.kubernetes.io/arch=amd64
                    beta.kubernetes.io/os=linux
                    kubernetes.io/arch=amd64
                    kubernetes.io/hostname=minikube
                    kubernetes.io/os=linux
                    minikube.k8s.io/commit=62e108c3dfdec8029a890ad6d8ef96b6461426dc
                    minikube.k8s.io/name=minikube
                    minikube.k8s.io/primary=true
                    minikube.k8s.io/updated_at=2022_09_18T14_28_50_0700
                    minikube.k8s.io/version=v1.26.1
                    node-role.kubernetes.io/control-plane=
                    node.kubernetes.io/exclude-from-external-load-balancers=
Annotations:        kubeadm.alpha.kubernetes.io/cri-socket: unix:///var/run/cri-dockerd.sock
                    volumes.kubernetes.io/controller-managed-attach-detach: true
CreationTimestamp:  Sun, 18 Sep 2022 18:28:47 +0000
Taints:             node.kubernetes.io/not-ready:NoSchedule
Unschedulable:      false
Lease:
  HolderIdentity:  minikube
  AcquireTime:     <unset>
  RenewTime:       Sun, 18 Sep 2022 18:29:00 +0000
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Sun, 18 Sep 2022 18:28:50 +0000   Sun, 18 Sep 2022 18:28:46 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Sun, 18 Sep 2022 18:28:50 +0000   Sun, 18 Sep 2022 18:28:46 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Sun, 18 Sep 2022 18:28:50 +0000   Sun, 18 Sep 2022 18:28:46 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            True    Sun, 18 Sep 2022 18:28:50 +0000   Sun, 18 Sep 2022 18:28:50 +0000   KubeletReady                 kubelet is posting ready status
Addresses:
  InternalIP:  192.168.49.2
  Hostname:    minikube
Capacity:
  cpu:                8
  ephemeral-storage:  263174212Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             12256300Ki
  pods:               110
Allocatable:
  cpu:                8
  ephemeral-storage:  263174212Ki
  hugepages-1Gi:      0
  hugepages-2Mi:      0
  memory:             12256300Ki
  pods:               110
System Info:
  Machine ID:                 4c192b04687c403f8fbb9bc7975b21b3
  System UUID:                4c192b04687c403f8fbb9bc7975b21b3
  Boot ID:                    73319a4f-fabe-4b51-95b9-32762b972ca0
  Kernel Version:             5.10.102.1-microsoft-standard-WSL2
  OS Image:                   Ubuntu 20.04.4 LTS
  Operating System:           linux
  Architecture:               amd64
  Container Runtime Version:  docker://20.10.17
  Kubelet Version:            v1.24.3
  Kube-Proxy Version:         v1.24.3
Non-terminated Pods:          (4 in total)
  Namespace                   Name                                CPU Requests  CPU Limits  Memory Requests  Memory Limits  Age
  ---------                   ----                                ------------  ----------  ---------------  -------------  ---
  kube-system                 etcd-minikube                       100m (1%!)(MISSING)     0 (0%!)(MISSING)      100Mi (0%!)(MISSING)       0 (0%!)(MISSING)         11s
  kube-system                 kube-apiserver-minikube             250m (3%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         14s
  kube-system                 kube-controller-manager-minikube    200m (2%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         12s
  kube-system                 kube-scheduler-minikube             100m (1%!)(MISSING)     0 (0%!)(MISSING)      0 (0%!)(MISSING)           0 (0%!)(MISSING)         12s
Allocated resources:
  (Total limits may be over 100 percent, i.e., overcommitted.)
  Resource           Requests    Limits
  --------           --------    ------
  cpu                650m (8%!)(MISSING)   0 (0%!)(MISSING)
  memory             100Mi (0%!)(MISSING)  0 (0%!)(MISSING)
  ephemeral-storage  0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-1Gi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
  hugepages-2Mi      0 (0%!)(MISSING)      0 (0%!)(MISSING)
Events:
  Type    Reason                   Age   From     Message
  ----    ------                   ----  ----     -------
  Normal  Starting                 12s   kubelet  Starting kubelet.
  Normal  NodeAllocatableEnforced  12s   kubelet  Updated Node Allocatable limit across pods
  Normal  NodeHasSufficientMemory  12s   kubelet  Node minikube status is now: NodeHasSufficientMemory
  Normal  NodeHasNoDiskPressure    12s   kubelet  Node minikube status is now: NodeHasNoDiskPressure
  Normal  NodeHasSufficientPID     12s   kubelet  Node minikube status is now: NodeHasSufficientPID
  Normal  NodeReady                12s   kubelet  Node minikube status is now: NodeReady


==> dmesg <==
[  +0.000001] FS-Cache: O-key=[10] '34323934393337363334'
[  +0.000005] FS-Cache: N-cookie c=00000000be61466a [p=000000003138294d fl=2 nc=0 na=1]
[  +0.000000] FS-Cache: N-cookie d=000000009d8edfe1 n=000000004db9af58
[  +0.000001] FS-Cache: N-key=[10] '34323934393337363334'
[  +0.156368] FS-Cache: Duplicate cookie detected
[  +0.000003] FS-Cache: O-cookie c=000000007c9a2569 [p=000000003138294d fl=222 nc=0 na=1]
[  +0.000001] FS-Cache: O-cookie d=000000009d8edfe1 n=00000000148c1a71
[  +0.000000] FS-Cache: O-key=[10] '34323934393337363530'
[  +0.000005] FS-Cache: N-cookie c=00000000cbcd5b96 [p=000000003138294d fl=2 nc=0 na=1]
[  +0.000001] FS-Cache: N-cookie d=000000009d8edfe1 n=0000000051c2a155
[  +0.000000] FS-Cache: N-key=[10] '34323934393337363530'
[  +0.000255] init: (1) ERROR: ConfigApplyWindowsLibPath:2474: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000002]  failed 2
[  +0.002653] FS-Cache: Duplicate cookie detected
[  +0.000003] FS-Cache: O-cookie c=000000007c9a2569 [p=000000003138294d fl=222 nc=0 na=1]
[  +0.000001] FS-Cache: O-cookie d=000000009d8edfe1 n=00000000148c1a71
[  +0.000001] FS-Cache: O-key=[10] '34323934393337363530'
[  +0.000005] FS-Cache: N-cookie c=00000000cbcd5b96 [p=000000003138294d fl=2 nc=0 na=1]
[  +0.000001] FS-Cache: N-cookie d=000000009d8edfe1 n=00000000c7276a1f
[  +0.000000] FS-Cache: N-key=[10] '34323934393337363530'
[  +0.010857] WARNING: /usr/share/zoneinfo/America/New_York not found. Is the tzdata package installed?
[  +1.153986] FS-Cache: Duplicate cookie detected
[  +0.000002] FS-Cache: O-cookie c=00000000be61466a [p=000000003138294d fl=222 nc=0 na=1]
[  +0.000001] FS-Cache: O-cookie d=000000009d8edfe1 n=000000009834b70b
[  +0.000000] FS-Cache: O-key=[10] '34323934393337373637'
[  +0.000004] FS-Cache: N-cookie c=000000000e643f60 [p=000000003138294d fl=2 nc=0 na=1]
[  +0.000001] FS-Cache: N-cookie d=000000009d8edfe1 n=00000000de734337
[  +0.000000] FS-Cache: N-key=[10] '34323934393337373637'
[  +0.203016] FS-Cache: Duplicate cookie detected
[  +0.000003] FS-Cache: O-cookie c=000000005ff57bd2 [p=000000003138294d fl=222 nc=0 na=1]
[  +0.000001] FS-Cache: O-cookie d=000000009d8edfe1 n=000000002abbc26d
[  +0.000001] FS-Cache: O-key=[10] '34323934393337373837'
[  +0.000005] FS-Cache: N-cookie c=00000000ddb9fe7f [p=000000003138294d fl=2 nc=0 na=1]
[  +0.000000] FS-Cache: N-cookie d=000000009d8edfe1 n=00000000a84f223c
[  +0.000001] FS-Cache: N-key=[10] '34323934393337373837'
[  +0.000310] init: (1) ERROR: ConfigApplyWindowsLibPath:2474: open /etc/ld.so.conf.d/ld.wsl.conf
[  +0.000003]  failed 2
[  +0.001274] init: (2) ERROR: UtilCreateProcessAndWait:653: /bin/mount failed with 2
[  +0.000131] init: (1) ERROR: UtilCreateProcessAndWait:673: /bin/mount failed with status 0x
[  +0.000002] ff00
[  +0.000007] init: (1) ERROR: ConfigMountFsTab:2529: Processing fstab with mount -a failed.
[  +0.011285] WARNING: /usr/share/zoneinfo/America/New_York not found. Is the tzdata package installed?
[  +0.101255] init: (8) ERROR: CreateProcessEntryCommon:440: getpwuid(0) failed 2
[  +0.000005] init: (8) ERROR: CreateProcessEntryCommon:443: getpwuid(0) failed 2
[  +0.020284] FS-Cache: Duplicate cookie detected
[  +0.000004] FS-Cache: O-cookie c=00000000cf530133 [p=000000003138294d fl=222 nc=0 na=1]
[  +0.000001] FS-Cache: O-cookie d=000000009d8edfe1 n=00000000f021070a
[  +0.000001] FS-Cache: O-key=[10] '34323934393337383031'
[  +0.000006] FS-Cache: N-cookie c=000000009fdecda0 [p=000000003138294d fl=2 nc=0 na=1]
[  +0.000000] FS-Cache: N-cookie d=000000009d8edfe1 n=00000000f35f2d95
[  +0.000001] FS-Cache: N-key=[10] '34323934393337383031'
[  +0.283305] FS-Cache: Duplicate cookie detected
[  +0.000003] FS-Cache: O-cookie c=000000004677400f [p=000000003138294d fl=222 nc=0 na=1]
[  +0.000000] FS-Cache: O-cookie d=000000009d8edfe1 n=000000002d99d7d3
[  +0.000001] FS-Cache: O-key=[10] '34323934393337383239'
[  +0.000004] FS-Cache: N-cookie c=00000000ef4c11d4 [p=000000003138294d fl=2 nc=0 na=1]
[  +0.000000] FS-Cache: N-cookie d=000000009d8edfe1 n=00000000f4f960f5
[  +0.000001] FS-Cache: N-key=[10] '34323934393337383239'
[  +2.836164] cgroup: runc (757) created nested cgroup for controller "memory" which has incomplete hierarchy support. Nested cgroups may change behavior in the future.
[  +0.000001] cgroup: "memory" requires setting use_hierarchy to 1 on the root


==> etcd [f63397277d97] <==
{"level":"info","ts":"2022-09-18T18:28:44.917Z","caller":"etcdmain/etcd.go:73","msg":"Running: ","args":["etcd","--advertise-client-urls=https://192.168.49.2:2379","--cert-file=/var/lib/minikube/certs/etcd/server.crt","--client-cert-auth=true","--data-dir=/var/lib/minikube/etcd","--experimental-initial-corrupt-check=true","--initial-advertise-peer-urls=https://192.168.49.2:2380","--initial-cluster=minikube=https://192.168.49.2:2380","--key-file=/var/lib/minikube/certs/etcd/server.key","--listen-client-urls=https://127.0.0.1:2379,https://192.168.49.2:2379","--listen-metrics-urls=http://127.0.0.1:2381","--listen-peer-urls=https://192.168.49.2:2380","--name=minikube","--peer-cert-file=/var/lib/minikube/certs/etcd/peer.crt","--peer-client-cert-auth=true","--peer-key-file=/var/lib/minikube/certs/etcd/peer.key","--peer-trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt","--proxy-refresh-interval=70000","--snapshot-count=10000","--trusted-ca-file=/var/lib/minikube/certs/etcd/ca.crt"]}
{"level":"info","ts":"2022-09-18T18:28:44.918Z","caller":"embed/etcd.go:131","msg":"configuring peer listeners","listen-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2022-09-18T18:28:44.918Z","caller":"embed/etcd.go:479","msg":"starting with peer TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/peer.crt, key = /var/lib/minikube/certs/etcd/peer.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2022-09-18T18:28:44.918Z","caller":"embed/etcd.go:139","msg":"configuring client listeners","listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"]}
{"level":"info","ts":"2022-09-18T18:28:44.918Z","caller":"embed/etcd.go:308","msg":"starting an etcd server","etcd-version":"3.5.3","git-sha":"0452feec7","go-version":"go1.16.15","go-os":"linux","go-arch":"amd64","max-cpu-set":8,"max-cpu-available":8,"member-initialized":false,"name":"minikube","data-dir":"/var/lib/minikube/etcd","wal-dir":"","wal-dir-dedicated":"","member-dir":"/var/lib/minikube/etcd/member","force-new-cluster":false,"heartbeat-interval":"100ms","election-timeout":"1s","initial-election-tick-advance":true,"snapshot-count":10000,"snapshot-catchup-entries":5000,"initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"],"cors":["*"],"host-whitelist":["*"],"initial-cluster":"minikube=https://192.168.49.2:2380","initial-cluster-state":"new","initial-cluster-token":"etcd-cluster","quota-size-bytes":2147483648,"pre-vote":true,"initial-corrupt-check":true,"corrupt-check-time-interval":"0s","auto-compaction-mode":"periodic","auto-compaction-retention":"0s","auto-compaction-interval":"0s","discovery-url":"","discovery-proxy":"","downgrade-check-interval":"5s"}
{"level":"info","ts":"2022-09-18T18:28:44.924Z","caller":"etcdserver/backend.go:81","msg":"opened backend db","path":"/var/lib/minikube/etcd/member/snap/db","took":"5.0458ms"}
{"level":"info","ts":"2022-09-18T18:28:44.935Z","caller":"etcdserver/raft.go:448","msg":"starting local member","local-member-id":"aec36adc501070cc","cluster-id":"fa54960ea34d58be"}
{"level":"info","ts":"2022-09-18T18:28:44.935Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=()"}
{"level":"info","ts":"2022-09-18T18:28:44.935Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 0"}
{"level":"info","ts":"2022-09-18T18:28:44.935Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"newRaft aec36adc501070cc [peers: [], term: 0, commit: 0, applied: 0, lastindex: 0, lastterm: 0]"}
{"level":"info","ts":"2022-09-18T18:28:44.935Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became follower at term 1"}
{"level":"info","ts":"2022-09-18T18:28:44.935Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"warn","ts":"2022-09-18T18:28:44.951Z","caller":"auth/store.go:1220","msg":"simple token is not cryptographically signed"}
{"level":"info","ts":"2022-09-18T18:28:44.956Z","caller":"mvcc/kvstore.go:415","msg":"kvstore restored","current-rev":1}
{"level":"info","ts":"2022-09-18T18:28:44.961Z","caller":"etcdserver/quota.go:94","msg":"enabled backend quota with default value","quota-name":"v3-applier","quota-size-bytes":2147483648,"quota-size":"2.1 GB"}
{"level":"info","ts":"2022-09-18T18:28:44.965Z","caller":"etcdserver/server.go:851","msg":"starting etcd server","local-member-id":"aec36adc501070cc","local-server-version":"3.5.3","cluster-version":"to_be_decided"}
{"level":"info","ts":"2022-09-18T18:28:44.965Z","caller":"etcdserver/server.go:736","msg":"started as single-node; fast-forwarding election ticks","local-member-id":"aec36adc501070cc","forward-ticks":9,"forward-duration":"900ms","election-ticks":10,"election-timeout":"1s"}
{"level":"info","ts":"2022-09-18T18:28:44.966Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc switched to configuration voters=(12593026477526642892)"}
{"level":"info","ts":"2022-09-18T18:28:44.966Z","caller":"membership/cluster.go:421","msg":"added member","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","added-peer-id":"aec36adc501070cc","added-peer-peer-urls":["https://192.168.49.2:2380"]}
{"level":"info","ts":"2022-09-18T18:28:44.968Z","caller":"embed/etcd.go:688","msg":"starting with client TLS","tls-info":"cert = /var/lib/minikube/certs/etcd/server.crt, key = /var/lib/minikube/certs/etcd/server.key, client-cert=, client-key=, trusted-ca = /var/lib/minikube/certs/etcd/ca.crt, client-cert-auth = true, crl-file = ","cipher-suites":[]}
{"level":"info","ts":"2022-09-18T18:28:44.969Z","caller":"embed/etcd.go:581","msg":"serving peer traffic","address":"192.168.49.2:2380"}
{"level":"info","ts":"2022-09-18T18:28:44.969Z","caller":"embed/etcd.go:553","msg":"cmux::serve","address":"192.168.49.2:2380"}
{"level":"info","ts":"2022-09-18T18:28:44.969Z","caller":"embed/etcd.go:277","msg":"now serving peer/client/metrics","local-member-id":"aec36adc501070cc","initial-advertise-peer-urls":["https://192.168.49.2:2380"],"listen-peer-urls":["https://192.168.49.2:2380"],"advertise-client-urls":["https://192.168.49.2:2379"],"listen-client-urls":["https://127.0.0.1:2379","https://192.168.49.2:2379"],"listen-metrics-urls":["http://127.0.0.1:2381"]}
{"level":"info","ts":"2022-09-18T18:28:44.969Z","caller":"embed/etcd.go:763","msg":"serving metrics","address":"http://127.0.0.1:2381"}
{"level":"info","ts":"2022-09-18T18:28:45.735Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc is starting a new election at term 1"}
{"level":"info","ts":"2022-09-18T18:28:45.735Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became pre-candidate at term 1"}
{"level":"info","ts":"2022-09-18T18:28:45.735Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgPreVoteResp from aec36adc501070cc at term 1"}
{"level":"info","ts":"2022-09-18T18:28:45.735Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became candidate at term 2"}
{"level":"info","ts":"2022-09-18T18:28:45.735Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc received MsgVoteResp from aec36adc501070cc at term 2"}
{"level":"info","ts":"2022-09-18T18:28:45.735Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"aec36adc501070cc became leader at term 2"}
{"level":"info","ts":"2022-09-18T18:28:45.735Z","logger":"raft","caller":"etcdserver/zap_raft.go:77","msg":"raft.node: aec36adc501070cc elected leader aec36adc501070cc at term 2"}
{"level":"info","ts":"2022-09-18T18:28:45.736Z","caller":"etcdserver/server.go:2507","msg":"setting up initial cluster version using v2 API","cluster-version":"3.5"}
{"level":"info","ts":"2022-09-18T18:28:45.738Z","caller":"membership/cluster.go:584","msg":"set initial cluster version","cluster-id":"fa54960ea34d58be","local-member-id":"aec36adc501070cc","cluster-version":"3.5"}
{"level":"info","ts":"2022-09-18T18:28:45.738Z","caller":"api/capability.go:75","msg":"enabled capabilities for version","cluster-version":"3.5"}
{"level":"info","ts":"2022-09-18T18:28:45.738Z","caller":"etcdserver/server.go:2531","msg":"cluster version is updated","cluster-version":"3.5"}
{"level":"info","ts":"2022-09-18T18:28:45.738Z","caller":"etcdserver/server.go:2042","msg":"published local member to cluster through raft","local-member-id":"aec36adc501070cc","local-member-attributes":"{Name:minikube ClientURLs:[https://192.168.49.2:2379]}","request-path":"/0/members/aec36adc501070cc/attributes","cluster-id":"fa54960ea34d58be","publish-timeout":"7s"}
{"level":"info","ts":"2022-09-18T18:28:45.738Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2022-09-18T18:28:45.738Z","caller":"embed/serve.go:98","msg":"ready to serve client requests"}
{"level":"info","ts":"2022-09-18T18:28:45.738Z","caller":"etcdmain/main.go:44","msg":"notifying init daemon"}
{"level":"info","ts":"2022-09-18T18:28:45.739Z","caller":"etcdmain/main.go:50","msg":"successfully notified init daemon"}
{"level":"info","ts":"2022-09-18T18:28:45.739Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"192.168.49.2:2379"}
{"level":"info","ts":"2022-09-18T18:28:45.739Z","caller":"embed/serve.go:188","msg":"serving client traffic securely","address":"127.0.0.1:2379"}


==> kernel <==
 18:29:02 up 32 min,  0 users,  load average: 1.62, 2.05, 1.95
Linux minikube 5.10.102.1-microsoft-standard-WSL2 #1 SMP Wed Mar 2 00:30:59 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
PRETTY_NAME="Ubuntu 20.04.4 LTS"


==> kube-apiserver [91fae8712e33] <==
W0918 18:28:46.475507       1 genericapiserver.go:557] Skipping API storage.k8s.io/v1alpha1 because it has no resources.
W0918 18:28:46.480149       1 genericapiserver.go:557] Skipping API flowcontrol.apiserver.k8s.io/v1alpha1 because it has no resources.
W0918 18:28:46.484818       1 genericapiserver.go:557] Skipping API apps/v1beta2 because it has no resources.
W0918 18:28:46.484893       1 genericapiserver.go:557] Skipping API apps/v1beta1 because it has no resources.
W0918 18:28:46.486551       1 genericapiserver.go:557] Skipping API admissionregistration.k8s.io/v1beta1 because it has no resources.
I0918 18:28:46.489537       1 plugins.go:158] Loaded 12 mutating admission controller(s) successfully in the following order: NamespaceLifecycle,LimitRanger,ServiceAccount,NodeRestriction,TaintNodesByCondition,Priority,DefaultTolerationSeconds,DefaultStorageClass,StorageObjectInUseProtection,RuntimeClass,DefaultIngressClass,MutatingAdmissionWebhook.
I0918 18:28:46.489568       1 plugins.go:161] Loaded 11 validating admission controller(s) successfully in the following order: LimitRanger,ServiceAccount,PodSecurity,Priority,PersistentVolumeClaimResize,RuntimeClass,CertificateApproval,CertificateSigning,CertificateSubjectRestriction,ValidatingAdmissionWebhook,ResourceQuota.
W0918 18:28:46.504400       1 genericapiserver.go:557] Skipping API apiregistration.k8s.io/v1beta1 because it has no resources.
I0918 18:28:47.466238       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0918 18:28:47.466384       1 secure_serving.go:210] Serving securely on [::]:8443
I0918 18:28:47.466410       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0918 18:28:47.466386       1 dynamic_serving_content.go:132] "Starting controller" name="serving-cert::/var/lib/minikube/certs/apiserver.crt::/var/lib/minikube/certs/apiserver.key"
I0918 18:28:47.466449       1 available_controller.go:491] Starting AvailableConditionController
I0918 18:28:47.466470       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
I0918 18:28:47.466476       1 cache.go:32] Waiting for caches to sync for AvailableConditionController controller
I0918 18:28:47.466618       1 controller.go:80] Starting OpenAPI V3 AggregationController
I0918 18:28:47.466673       1 apf_controller.go:317] Starting API Priority and Fairness config controller
I0918 18:28:47.466731       1 customresource_discovery_controller.go:209] Starting DiscoveryController
I0918 18:28:47.466768       1 dynamic_serving_content.go:132] "Starting controller" name="aggregator-proxy-cert::/var/lib/minikube/certs/front-proxy-client.crt::/var/lib/minikube/certs/front-proxy-client.key"
I0918 18:28:47.468684       1 autoregister_controller.go:141] Starting autoregister controller
I0918 18:28:47.468717       1 cache.go:32] Waiting for caches to sync for autoregister controller
I0918 18:28:47.468750       1 controller.go:83] Starting OpenAPI AggregationController
I0918 18:28:47.471163       1 crdregistration_controller.go:111] Starting crd-autoregister controller
I0918 18:28:47.471180       1 shared_informer.go:255] Waiting for caches to sync for crd-autoregister
I0918 18:28:47.478659       1 apiservice_controller.go:97] Starting APIServiceRegistrationController
I0918 18:28:47.478704       1 cache.go:32] Waiting for caches to sync for APIServiceRegistrationController controller
I0918 18:28:47.478678       1 establishing_controller.go:76] Starting EstablishingController
I0918 18:28:47.479892       1 controller.go:85] Starting OpenAPI controller
I0918 18:28:47.479943       1 controller.go:85] Starting OpenAPI V3 controller
I0918 18:28:47.479983       1 naming_controller.go:291] Starting NamingConditionController
I0918 18:28:47.480006       1 crd_finalizer.go:266] Starting CRDFinalizer
I0918 18:28:47.480041       1 nonstructuralschema_controller.go:192] Starting NonStructuralSchemaConditionController
I0918 18:28:47.480075       1 apiapproval_controller.go:186] Starting KubernetesAPIApprovalPolicyConformantConditionController
I0918 18:28:47.480584       1 cluster_authentication_trust_controller.go:440] Starting cluster_authentication_trust_controller controller
I0918 18:28:47.480611       1 shared_informer.go:255] Waiting for caches to sync for cluster_authentication_trust_controller
I0918 18:28:47.480650       1 dynamic_cafile_content.go:157] "Starting controller" name="client-ca-bundle::/var/lib/minikube/certs/ca.crt"
I0918 18:28:47.483867       1 dynamic_cafile_content.go:157] "Starting controller" name="request-header::/var/lib/minikube/certs/front-proxy-ca.crt"
I0918 18:28:47.503257       1 controller.go:611] quota admission added evaluator for: namespaces
I0918 18:28:47.566591       1 shared_informer.go:262] Caches are synced for node_authorizer
I0918 18:28:47.566592       1 cache.go:39] Caches are synced for AvailableConditionController controller
I0918 18:28:47.567768       1 apf_controller.go:322] Running API Priority and Fairness config worker
I0918 18:28:47.569037       1 cache.go:39] Caches are synced for autoregister controller
I0918 18:28:47.571613       1 shared_informer.go:262] Caches are synced for crd-autoregister
I0918 18:28:47.578747       1 cache.go:39] Caches are synced for APIServiceRegistrationController controller
I0918 18:28:47.581085       1 shared_informer.go:262] Caches are synced for cluster_authentication_trust_controller
I0918 18:28:48.278558       1 controller.go:132] OpenAPI AggregationController: action for item k8s_internal_local_delegation_chain_0000000000: Nothing (removed from the queue).
I0918 18:28:48.471838       1 storage_scheduling.go:95] created PriorityClass system-node-critical with value 2000001000
I0918 18:28:48.479247       1 storage_scheduling.go:95] created PriorityClass system-cluster-critical with value 2000000000
I0918 18:28:48.479285       1 storage_scheduling.go:111] all system priority classes are created successfully or already exist.
I0918 18:28:49.001245       1 controller.go:611] quota admission added evaluator for: roles.rbac.authorization.k8s.io
I0918 18:28:49.043774       1 controller.go:611] quota admission added evaluator for: rolebindings.rbac.authorization.k8s.io
I0918 18:28:49.123820       1 alloc.go:327] "allocated clusterIPs" service="default/kubernetes" clusterIPs=map[IPv4:10.96.0.1]
W0918 18:28:49.141317       1 lease.go:234] Resetting endpoints for master service "kubernetes" to [192.168.49.2]
I0918 18:28:49.142220       1 controller.go:611] quota admission added evaluator for: endpoints
I0918 18:28:49.146974       1 controller.go:611] quota admission added evaluator for: endpointslices.discovery.k8s.io
I0918 18:28:49.588568       1 controller.go:611] quota admission added evaluator for: serviceaccounts
I0918 18:28:50.525919       1 controller.go:611] quota admission added evaluator for: deployments.apps
I0918 18:28:50.533197       1 alloc.go:327] "allocated clusterIPs" service="kube-system/kube-dns" clusterIPs=map[IPv4:10.96.0.10]
I0918 18:28:50.544769       1 controller.go:611] quota admission added evaluator for: daemonsets.apps
I0918 18:28:50.605442       1 controller.go:611] quota admission added evaluator for: leases.coordination.k8s.io


==> kube-controller-manager [ff691578de00] <==
I0918 18:29:00.659418       1 shared_informer.go:255] Waiting for caches to sync for PV protection
I0918 18:29:00.966096       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for serviceaccounts
I0918 18:29:00.966139       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for horizontalpodautoscalers.autoscaling
I0918 18:29:00.966155       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for cronjobs.batch
I0918 18:29:00.966179       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for podtemplates
I0918 18:29:00.966204       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for deployments.apps
I0918 18:29:00.966235       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for daemonsets.apps
I0918 18:29:00.966280       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for poddisruptionbudgets.policy
W0918 18:29:00.966312       1 shared_informer.go:533] resyncPeriod 12h41m59.407037982s is smaller than resyncCheckPeriod 12h44m37.430295753s and the informer has already started. Changing it to 12h44m37.430295753s
I0918 18:29:00.966360       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for endpoints
I0918 18:29:00.966412       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for rolebindings.rbac.authorization.k8s.io
I0918 18:29:00.966460       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for csistoragecapacities.storage.k8s.io
I0918 18:29:00.966492       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for replicasets.apps
I0918 18:29:00.966524       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for leases.coordination.k8s.io
I0918 18:29:00.966541       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for limitranges
I0918 18:29:00.966559       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for controllerrevisions.apps
I0918 18:29:00.966594       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for networkpolicies.networking.k8s.io
I0918 18:29:00.966615       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for roles.rbac.authorization.k8s.io
I0918 18:29:00.966633       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for ingresses.networking.k8s.io
I0918 18:29:00.966674       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for events.events.k8s.io
I0918 18:29:00.966685       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for endpointslices.discovery.k8s.io
I0918 18:29:00.966701       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for statefulsets.apps
I0918 18:29:00.966762       1 resource_quota_monitor.go:233] QuotaMonitor created object count evaluator for jobs.batch
I0918 18:29:00.966809       1 controllermanager.go:593] Started "resourcequota"
I0918 18:29:00.966846       1 resource_quota_controller.go:273] Starting resource quota controller
I0918 18:29:00.966854       1 shared_informer.go:255] Waiting for caches to sync for resource quota
I0918 18:29:00.966898       1 resource_quota_monitor.go:308] QuotaMonitor running
I0918 18:29:01.214159       1 controllermanager.go:593] Started "namespace"
I0918 18:29:01.214218       1 namespace_controller.go:200] Starting namespace controller
I0918 18:29:01.214225       1 shared_informer.go:255] Waiting for caches to sync for namespace
I0918 18:29:01.357252       1 controllermanager.go:593] Started "clusterrole-aggregation"
I0918 18:29:01.357300       1 clusterroleaggregation_controller.go:194] Starting ClusterRoleAggregator
I0918 18:29:01.357311       1 shared_informer.go:255] Waiting for caches to sync for ClusterRoleAggregator
I0918 18:29:01.507317       1 controllermanager.go:593] Started "root-ca-cert-publisher"
I0918 18:29:01.507384       1 publisher.go:107] Starting root CA certificate configmap publisher
I0918 18:29:01.507392       1 shared_informer.go:255] Waiting for caches to sync for crt configmap
I0918 18:29:01.657453       1 controllermanager.go:593] Started "cronjob"
I0918 18:29:01.657521       1 cronjob_controllerv2.go:135] "Starting cronjob controller v2"
I0918 18:29:01.657530       1 shared_informer.go:255] Waiting for caches to sync for cronjob
I0918 18:29:01.807020       1 controllermanager.go:593] Started "pvc-protection"
I0918 18:29:01.807063       1 pvc_protection_controller.go:103] "Starting PVC protection controller"
I0918 18:29:01.807077       1 shared_informer.go:255] Waiting for caches to sync for PVC protection
I0918 18:29:01.957763       1 controllermanager.go:593] Started "ttl-after-finished"
I0918 18:29:01.957803       1 ttlafterfinished_controller.go:109] Starting TTL after finished controller
I0918 18:29:01.957811       1 shared_informer.go:255] Waiting for caches to sync for TTL after finished
I0918 18:29:02.106729       1 controllermanager.go:593] Started "persistentvolume-expander"
I0918 18:29:02.106759       1 expand_controller.go:341] Starting expand controller
I0918 18:29:02.106768       1 shared_informer.go:255] Waiting for caches to sync for expand
I0918 18:29:02.258066       1 controllermanager.go:593] Started "endpointslice"
I0918 18:29:02.258099       1 endpointslice_controller.go:257] Starting endpoint slice controller
I0918 18:29:02.258111       1 shared_informer.go:255] Waiting for caches to sync for endpoint_slice
I0918 18:29:02.407262       1 controllermanager.go:593] Started "endpointslicemirroring"
I0918 18:29:02.407287       1 endpointslicemirroring_controller.go:212] Starting EndpointSliceMirroring controller
I0918 18:29:02.407297       1 shared_informer.go:255] Waiting for caches to sync for endpoint_slice_mirroring
I0918 18:29:02.556227       1 controllermanager.go:593] Started "podgc"
I0918 18:29:02.556285       1 gc_controller.go:92] Starting GC controller
I0918 18:29:02.556291       1 shared_informer.go:255] Waiting for caches to sync for GC
I0918 18:29:02.707380       1 controllermanager.go:593] Started "serviceaccount"
I0918 18:29:02.707442       1 serviceaccounts_controller.go:117] Starting service account controller
I0918 18:29:02.707450       1 shared_informer.go:255] Waiting for caches to sync for service account


==> kube-scheduler [c060873942db] <==
W0918 18:28:47.484129       1 authentication.go:348] To require authentication configuration lookup to succeed, set --authentication-tolerate-lookup-failure=false
I0918 18:28:47.556710       1 server.go:147] "Starting Kubernetes Scheduler" version="v1.24.3"
I0918 18:28:47.556761       1 server.go:149] "Golang settings" GOGC="" GOMAXPROCS="" GOTRACEBACK=""
I0918 18:28:47.557992       1 configmap_cafile_content.go:202] "Starting controller" name="client-ca::kube-system::extension-apiserver-authentication::client-ca-file"
I0918 18:28:47.558051       1 secure_serving.go:210] Serving securely on 127.0.0.1:10259
I0918 18:28:47.558061       1 shared_informer.go:255] Waiting for caches to sync for client-ca::kube-system::extension-apiserver-authentication::client-ca-file
I0918 18:28:47.558098       1 tlsconfig.go:240] "Starting DynamicServingCertificateController"
W0918 18:28:47.558892       1 reflector.go:324] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0918 18:28:47.558935       1 reflector.go:138] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
W0918 18:28:47.559576       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0918 18:28:47.559611       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0918 18:28:47.559921       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
E0918 18:28:47.559958       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StorageClass: failed to list *v1.StorageClass: storageclasses.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "storageclasses" in API group "storage.k8s.io" at the cluster scope
W0918 18:28:47.560118       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
E0918 18:28:47.560138       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSINode: failed to list *v1.CSINode: csinodes.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csinodes" in API group "storage.k8s.io" at the cluster scope
W0918 18:28:47.560310       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0918 18:28:47.560322       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0918 18:28:47.560330       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
E0918 18:28:47.560355       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0918 18:28:47.560358       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Node: failed to list *v1.Node: nodes is forbidden: User "system:kube-scheduler" cannot list resource "nodes" in API group "" at the cluster scope
W0918 18:28:47.560390       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
E0918 18:28:47.560346       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0918 18:28:47.560461       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0918 18:28:47.560480       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0918 18:28:47.560305       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0918 18:28:47.560573       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0918 18:28:47.560390       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0918 18:28:47.560608       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0918 18:28:47.560410       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0918 18:28:47.560622       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0918 18:28:47.560410       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0918 18:28:47.560650       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0918 18:28:47.560433       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicationController: failed to list *v1.ReplicationController: replicationcontrollers is forbidden: User "system:kube-scheduler" cannot list resource "replicationcontrollers" in API group "" at the cluster scope
W0918 18:28:47.560440       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0918 18:28:47.560662       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0918 18:28:47.560809       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0918 18:28:47.560841       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0918 18:28:48.382621       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
E0918 18:28:48.382659       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.ReplicaSet: failed to list *v1.ReplicaSet: replicasets.apps is forbidden: User "system:kube-scheduler" cannot list resource "replicasets" in API group "apps" at the cluster scope
W0918 18:28:48.386728       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
E0918 18:28:48.386763       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Pod: failed to list *v1.Pod: pods is forbidden: User "system:kube-scheduler" cannot list resource "pods" in API group "" at the cluster scope
W0918 18:28:48.560062       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
E0918 18:28:48.560148       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIDriver: failed to list *v1.CSIDriver: csidrivers.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csidrivers" in API group "storage.k8s.io" at the cluster scope
W0918 18:28:48.568905       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
E0918 18:28:48.568942       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.CSIStorageCapacity: failed to list *v1.CSIStorageCapacity: csistoragecapacities.storage.k8s.io is forbidden: User "system:kube-scheduler" cannot list resource "csistoragecapacities" in API group "storage.k8s.io" at the cluster scope
W0918 18:28:48.572925       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
E0918 18:28:48.572972       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolumeClaim: failed to list *v1.PersistentVolumeClaim: persistentvolumeclaims is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumeclaims" in API group "" at the cluster scope
W0918 18:28:48.618922       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
E0918 18:28:48.618960       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Service: failed to list *v1.Service: services is forbidden: User "system:kube-scheduler" cannot list resource "services" in API group "" at the cluster scope
W0918 18:28:48.627797       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
E0918 18:28:48.627837       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PodDisruptionBudget: failed to list *v1.PodDisruptionBudget: poddisruptionbudgets.policy is forbidden: User "system:kube-scheduler" cannot list resource "poddisruptionbudgets" in API group "policy" at the cluster scope
W0918 18:28:48.695118       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
E0918 18:28:48.695153       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.StatefulSet: failed to list *v1.StatefulSet: statefulsets.apps is forbidden: User "system:kube-scheduler" cannot list resource "statefulsets" in API group "apps" at the cluster scope
W0918 18:28:48.705094       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
E0918 18:28:48.705131       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.PersistentVolume: failed to list *v1.PersistentVolume: persistentvolumes is forbidden: User "system:kube-scheduler" cannot list resource "persistentvolumes" in API group "" at the cluster scope
W0918 18:28:48.809372       1 reflector.go:324] vendor/k8s.io/client-go/informers/factory.go:134: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
E0918 18:28:48.809407       1 reflector.go:138] vendor/k8s.io/client-go/informers/factory.go:134: Failed to watch *v1.Namespace: failed to list *v1.Namespace: namespaces is forbidden: User "system:kube-scheduler" cannot list resource "namespaces" in API group "" at the cluster scope
W0918 18:28:48.995604       1 reflector.go:324] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
E0918 18:28:48.995643       1 reflector.go:138] pkg/server/dynamiccertificates/configmap_cafile_content.go:206: Failed to watch *v1.ConfigMap: failed to list *v1.ConfigMap: configmaps "extension-apiserver-authentication" is forbidden: User "system:kube-scheduler" cannot list resource "configmaps" in API group "" in the namespace "kube-system"
I0918 18:28:51.258346       1 shared_informer.go:262] Caches are synced for client-ca::kube-system::extension-apiserver-authentication::client-ca-file


==> kubelet <==
-- Logs begin at Sun 2022-09-18 18:28:29 UTC, end at Sun 2022-09-18 18:29:02 UTC. --
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.575269    2093 topology_manager.go:133] "Creating topology manager with policy per scope" topologyPolicyName="none" topologyScopeName="container"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.575281    2093 container_manager_linux.go:302] "Creating device plugin manager" devicePluginEnabled=true
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.575310    2093 state_mem.go:36] "Initialized new in-memory state store"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.575374    2093 util_unix.go:104] "Using this format as endpoint is deprecated, please consider using full url format." deprecatedFormat="/var/run/cri-dockerd.sock" fullURLFormat="unix:///var/run/cri-dockerd.sock"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.576784    2093 util_unix.go:104] "Using this format as endpoint is deprecated, please consider using full url format." deprecatedFormat="/var/run/cri-dockerd.sock" fullURLFormat="unix:///var/run/cri-dockerd.sock"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.577506    2093 kubelet.go:376] "Attempting to sync node with API server"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.577544    2093 kubelet.go:267] "Adding static pod path" path="/etc/kubernetes/manifests"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.577563    2093 kubelet.go:278] "Adding apiserver pod source"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.577577    2093 apiserver.go:42] "Waiting for node sync before watching apiserver pods"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.589366    2093 kuberuntime_manager.go:239] "Container runtime initialized" containerRuntime="docker" version="20.10.17" apiVersion="1.41.0"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.591719    2093 server.go:1181] "Started kubelet"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.592743    2093 server.go:150] "Starting to listen" address="0.0.0.0" port=10250
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.593692    2093 fs_resource_analyzer.go:67] "Starting FS ResourceAnalyzer"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.593908    2093 volume_manager.go:289] "Starting Kubelet Volume Manager"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.594036    2093 server.go:410] "Adding debug handlers to kubelet server"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.594079    2093 desired_state_of_world_populator.go:145] "Desired state populator starts to run"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.623705    2093 kubelet_network_linux.go:76] "Initialized protocol iptables rules." protocol=IPv4
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.639037    2093 kubelet_network_linux.go:76] "Initialized protocol iptables rules." protocol=IPv6
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.639073    2093 status_manager.go:161] "Starting to sync pod status with apiserver"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.639090    2093 kubelet.go:1986] "Starting kubelet main sync loop"
Sep 18 18:28:50 minikube kubelet[2093]: E0918 18:28:50.639122    2093 kubelet.go:2010] "Skipping pod synchronization" err="[container runtime status check may not have completed yet, PLEG is not healthy: pleg has yet to be successful]"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.685635    2093 cpu_manager.go:213] "Starting CPU manager" policy="none"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.685683    2093 cpu_manager.go:214] "Reconciling" reconcilePeriod="10s"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.685704    2093 state_mem.go:36] "Initialized new in-memory state store"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.685894    2093 state_mem.go:88] "Updated default CPUSet" cpuSet=""
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.685913    2093 state_mem.go:96] "Updated CPUSet assignments" assignments=map[]
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.685920    2093 policy_none.go:49] "None policy: Start"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.688821    2093 memory_manager.go:168] "Starting memorymanager" policy="None"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.688868    2093 state_mem.go:35] "Initializing new in-memory state store"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.689001    2093 state_mem.go:75] "Updated machine memory state"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.691540    2093 manager.go:610] "Failed to read data from checkpoint" checkpoint="kubelet_internal_checkpoint" err="checkpoint is not found"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.691822    2093 plugin_manager.go:114] "Starting Kubelet Plugin Manager"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.701487    2093 kubelet_node_status.go:70] "Attempting to register node" node="minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.714233    2093 kubelet_node_status.go:108] "Node was previously registered" node="minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.714327    2093 kubelet_node_status.go:73] "Successfully registered node" node="minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.739510    2093 topology_manager.go:200] "Topology Admit Handler"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.739629    2093 topology_manager.go:200] "Topology Admit Handler"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.739658    2093 topology_manager.go:200] "Topology Admit Handler"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.739678    2093 topology_manager.go:200] "Topology Admit Handler"
Sep 18 18:28:50 minikube kubelet[2093]: E0918 18:28:50.788221    2093 kubelet.go:1690] "Failed creating a mirror pod for" err="pods \"kube-apiserver-minikube\" already exists" pod="kube-system/kube-apiserver-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.894693    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"flexvolume-dir\" (UniqueName: \"kubernetes.io/host-path/76444121a189d8a30add20fb32ab6d4e-flexvolume-dir\") pod \"kube-controller-manager-minikube\" (UID: \"76444121a189d8a30add20fb32ab6d4e\") " pod="kube-system/kube-controller-manager-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.894750    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/76444121a189d8a30add20fb32ab6d4e-k8s-certs\") pod \"kube-controller-manager-minikube\" (UID: \"76444121a189d8a30add20fb32ab6d4e\") " pod="kube-system/kube-controller-manager-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.894773    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/af8a252bb89a737e9c95199d01283487-ca-certs\") pod \"kube-apiserver-minikube\" (UID: \"af8a252bb89a737e9c95199d01283487\") " pod="kube-system/kube-apiserver-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.894787    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"ca-certs\" (UniqueName: \"kubernetes.io/host-path/76444121a189d8a30add20fb32ab6d4e-ca-certs\") pod \"kube-controller-manager-minikube\" (UID: \"76444121a189d8a30add20fb32ab6d4e\") " pod="kube-system/kube-controller-manager-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.894956    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-data\" (UniqueName: \"kubernetes.io/host-path/906edd533192a4db2396a938662a5271-etcd-data\") pod \"etcd-minikube\" (UID: \"906edd533192a4db2396a938662a5271\") " pod="kube-system/etcd-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895022    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/af8a252bb89a737e9c95199d01283487-usr-local-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"af8a252bb89a737e9c95199d01283487\") " pod="kube-system/kube-apiserver-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895078    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/af8a252bb89a737e9c95199d01283487-usr-share-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"af8a252bb89a737e9c95199d01283487\") " pod="kube-system/kube-apiserver-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895122    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/76444121a189d8a30add20fb32ab6d4e-etc-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"76444121a189d8a30add20fb32ab6d4e\") " pod="kube-system/kube-controller-manager-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895164    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etc-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/af8a252bb89a737e9c95199d01283487-etc-ca-certificates\") pod \"kube-apiserver-minikube\" (UID: \"af8a252bb89a737e9c95199d01283487\") " pod="kube-system/kube-apiserver-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895243    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/76444121a189d8a30add20fb32ab6d4e-kubeconfig\") pod \"kube-controller-manager-minikube\" (UID: \"76444121a189d8a30add20fb32ab6d4e\") " pod="kube-system/kube-controller-manager-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895320    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/76444121a189d8a30add20fb32ab6d4e-usr-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"76444121a189d8a30add20fb32ab6d4e\") " pod="kube-system/kube-controller-manager-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895346    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"kubeconfig\" (UniqueName: \"kubernetes.io/host-path/2e95d5efbc70e877d20097c03ba4ff89-kubeconfig\") pod \"kube-scheduler-minikube\" (UID: \"2e95d5efbc70e877d20097c03ba4ff89\") " pod="kube-system/kube-scheduler-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895366    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"etcd-certs\" (UniqueName: \"kubernetes.io/host-path/906edd533192a4db2396a938662a5271-etcd-certs\") pod \"etcd-minikube\" (UID: \"906edd533192a4db2396a938662a5271\") " pod="kube-system/etcd-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895387    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"k8s-certs\" (UniqueName: \"kubernetes.io/host-path/af8a252bb89a737e9c95199d01283487-k8s-certs\") pod \"kube-apiserver-minikube\" (UID: \"af8a252bb89a737e9c95199d01283487\") " pod="kube-system/kube-apiserver-minikube"
Sep 18 18:28:50 minikube kubelet[2093]: I0918 18:28:50.895408    2093 reconciler.go:270] "operationExecutor.VerifyControllerAttachedVolume started for volume \"usr-local-share-ca-certificates\" (UniqueName: \"kubernetes.io/host-path/76444121a189d8a30add20fb32ab6d4e-usr-local-share-ca-certificates\") pod \"kube-controller-manager-minikube\" (UID: \"76444121a189d8a30add20fb32ab6d4e\") " pod="kube-system/kube-controller-manager-minikube"
Sep 18 18:28:51 minikube kubelet[2093]: I0918 18:28:51.578955    2093 apiserver.go:52] "Watching apiserver"
Sep 18 18:28:51 minikube kubelet[2093]: I0918 18:28:51.800879    2093 reconciler.go:157] "Reconciler: start to sync state"
Sep 18 18:28:52 minikube kubelet[2093]: E0918 18:28:52.186718    2093 kubelet.go:1690] "Failed creating a mirror pod for" err="pods \"etcd-minikube\" already exists" pod="kube-system/etcd-minikube"
Sep 18 18:28:52 minikube kubelet[2093]: E0918 18:28:52.388824    2093 kubelet.go:1690] "Failed creating a mirror pod for" err="pods \"kube-apiserver-minikube\" already exists" pod="kube-system/kube-apiserver-minikube"
Sep 18 18:28:52 minikube kubelet[2093]: E0918 18:28:52.587657    2093 kubelet.go:1690] "Failed creating a mirror pod for" err="pods \"kube-controller-manager-minikube\" already exists" pod="kube-system/kube-controller-manager-minikube"

